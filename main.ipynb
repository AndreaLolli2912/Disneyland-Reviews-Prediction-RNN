{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 64530,
     "status": "ok",
     "timestamp": 1688310479793,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "DY0G-TJvACbP",
    "outputId": "5d993ae7-839b-4249-c0c5-fc4cf60f6599"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: contractions in /home/andrea/anaconda3/lib/python3.9/site-packages (0.1.73)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in /home/andrea/anaconda3/lib/python3.9/site-packages (from contractions) (0.0.24)\n",
      "Requirement already satisfied: pyahocorasick in /home/andrea/anaconda3/lib/python3.9/site-packages (from textsearch>=0.0.21->contractions) (2.0.0)\n",
      "Requirement already satisfied: anyascii in /home/andrea/anaconda3/lib/python3.9/site-packages (from textsearch>=0.0.21->contractions) (0.3.2)\n",
      "Requirement already satisfied: langdetect in /home/andrea/anaconda3/lib/python3.9/site-packages (1.0.9)\n",
      "Requirement already satisfied: six in /home/andrea/anaconda3/lib/python3.9/site-packages (from langdetect) (1.16.0)\n",
      "Reading package lists... Done\n",
      "\u001b[1;31mE: \u001b[0mCould not open lock file /var/lib/apt/lists/lock - open (13: Permission denied)\u001b[0m\n",
      "\u001b[1;31mE: \u001b[0mUnable to lock directory /var/lib/apt/lists/\u001b[0m\n",
      "\u001b[1;33mW: \u001b[0mProblem unlinking the file /var/cache/apt/pkgcache.bin - RemoveCaches (13: Permission denied)\u001b[0m\n",
      "\u001b[1;33mW: \u001b[0mProblem unlinking the file /var/cache/apt/srcpkgcache.bin - RemoveCaches (13: Permission denied)\u001b[0m\n",
      "\u001b[1;31mE: \u001b[0mCould not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\u001b[0m\n",
      "\u001b[1;31mE: \u001b[0mUnable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\u001b[0m\n",
      "\u001b[1;31mE: \u001b[0mCould not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\u001b[0m\n",
      "\u001b[1;31mE: \u001b[0mUnable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\u001b[0m\n",
      "Requirement already satisfied: pyenchant in /home/andrea/anaconda3/lib/python3.9/site-packages (3.2.2)\n",
      "Requirement already satisfied: pyenchant in /home/andrea/anaconda3/lib/python3.9/site-packages (3.2.2)\n",
      "Requirement already satisfied: scikeras in /home/andrea/anaconda3/lib/python3.9/site-packages (0.10.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in /home/andrea/anaconda3/lib/python3.9/site-packages (from scikeras) (1.0.2)\n",
      "Requirement already satisfied: packaging>=0.21 in /home/andrea/anaconda3/lib/python3.9/site-packages (from scikeras) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/andrea/anaconda3/lib/python3.9/site-packages (from packaging>=0.21->scikeras) (3.0.9)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/andrea/anaconda3/lib/python3.9/site-packages (from scikit-learn>=1.0.0->scikeras) (1.7.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/andrea/anaconda3/lib/python3.9/site-packages (from scikit-learn>=1.0.0->scikeras) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/andrea/anaconda3/lib/python3.9/site-packages (from scikit-learn>=1.0.0->scikeras) (2.2.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in /home/andrea/anaconda3/lib/python3.9/site-packages (from scikit-learn>=1.0.0->scikeras) (1.22.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install contractions\n",
    "!pip install langdetect\n",
    "\n",
    "!apt update\n",
    "!apt install enchant --fix-missing\n",
    "!apt install -qq enchant\n",
    "!pip install pyenchant\n",
    "\n",
    "!pip install pyenchant\n",
    "!pip install scikeras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 633,
     "status": "ok",
     "timestamp": 1688312238644,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "T6rLFiKNAFGh",
    "outputId": "9cf3c8f3-e4b8-47f7-a2ba-bbff027e7654"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/andrea/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/andrea/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/andrea/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Embedding, GRU, Flatten, Dense, BatchNormalization, Dropout, Concatenate, Lambda\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from scipy.linalg import svd\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_recall_curve, roc_curve, confusion_matrix\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "import enchant\n",
    "import contractions\n",
    "import re\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sgANGPkuCOI3"
   },
   "source": [
    "# 1) Input\n",
    "- **Which fields to be used to predict the rating?**\n",
    "\n",
    "For the purpose of predicting the rating, three key fields have been selected: \"Review_Text,\" \"Year_Month,\" and \"Branch.\" Each of these fields contributes valuable insights to the analysis.\n",
    "\n",
    "The field <code>Review_Text</code> holds utmost significance as it encompasses the primary feature of the dataset. It comprises the customers' feedback and reviews regarding the amusement park. Analyzing the textual data allows for the identification of sentiment, key themes, and specific aspects of the park that are frequently mentioned. Applying appropriate Natural Language Processing (NLP) techniques facilitates the extraction of meaningful information from the text.\n",
    "\n",
    "The <code>Year_Month</code> field provides temporal information, allowing for the observation of patterns and trends over time. By considering the month and year of each review, it becomes possible to identify seasonal variations in customer satisfaction or changes in the park's offerings and management practices that may influence ratings.\n",
    "\n",
    "Additionally, the <code>Branch</code> field indicates the specific location or branch of the amusement park. Analyzing ratings based on different branches enables the identification of potential variations in customer experiences across locations. This analysis may shed light on unique characteristics or operational differences between branches that contribute to differences in customer satisfaction.\n",
    "\n",
    "By incorporating these three fields as input features for rating prediction, the analysis encompasses textual information, temporal trends, and location-specific patterns. This comprehensive approach aims to gain a deeper understanding of the factors influencing customer ratings at the amusement park."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 2079,
     "status": "ok",
     "timestamp": 1688310487937,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "z5jFZVRcxGcW",
    "outputId": "cf29d081-17a0-4018-f627-7dc12abfb4e1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review_ID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Year_Month</th>\n",
       "      <th>Reviewer_Location</th>\n",
       "      <th>Review_Text</th>\n",
       "      <th>Branch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>670772142</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-4</td>\n",
       "      <td>Australia</td>\n",
       "      <td>If you've ever been to Disneyland anywhere you...</td>\n",
       "      <td>Disneyland_HongKong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>670682799</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-5</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>Its been a while since d last time we visit HK...</td>\n",
       "      <td>Disneyland_HongKong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>670623270</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-4</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>Thanks God it wasn   t too hot or too humid wh...</td>\n",
       "      <td>Disneyland_HongKong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>670607911</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-4</td>\n",
       "      <td>Australia</td>\n",
       "      <td>HK Disneyland is a great compact park. Unfortu...</td>\n",
       "      <td>Disneyland_HongKong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>670607296</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-4</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>the location is not in the city, took around 1...</td>\n",
       "      <td>Disneyland_HongKong</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Review_ID  Rating Year_Month     Reviewer_Location  \\\n",
       "0  670772142       4     2019-4             Australia   \n",
       "1  670682799       4     2019-5           Philippines   \n",
       "2  670623270       4     2019-4  United Arab Emirates   \n",
       "3  670607911       4     2019-4             Australia   \n",
       "4  670607296       4     2019-4        United Kingdom   \n",
       "\n",
       "                                         Review_Text               Branch  \n",
       "0  If you've ever been to Disneyland anywhere you...  Disneyland_HongKong  \n",
       "1  Its been a while since d last time we visit HK...  Disneyland_HongKong  \n",
       "2  Thanks God it wasn   t too hot or too humid wh...  Disneyland_HongKong  \n",
       "3  HK Disneyland is a great compact park. Unfortu...  Disneyland_HongKong  \n",
       "4  the location is not in the city, took around 1...  Disneyland_HongKong  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read dataset\n",
    "df = pd.read_csv(\"https://github.com/MikiTwenty/Python/blob/main/Colab/DL-Exam/parkReviews.csv?raw=true\", encoding='latin-1')\n",
    "df = df.replace('missing', np.nan)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1688310487938,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "nQ4v62ZqAGun",
    "outputId": "43654e6c-3f7b-4d39-ef80-4cf9c09cdd17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(X): 8532\n",
      "len(y): 8532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# extract reviews, year, month, branch and labels\n",
    "\n",
    "X = df[['Review_Text', 'Year_Month', 'Branch']]\n",
    "       \n",
    "y = df['Rating']\n",
    "\n",
    "# Create a copy of X before modifying it\n",
    "X_copy = X.copy()\n",
    "\n",
    "\n",
    "# Reduce dataset size by 80%\n",
    "X_trash, X_cut, y_trash, y_cut = train_test_split(X_copy, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Rename reduced dataset\n",
    "X, y = X_cut, y_cut\n",
    "\n",
    "print(f\"len(X): {len(X)}\")\n",
    "print(f\"len(y): {len(y)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review_Text</th>\n",
       "      <th>Year_Month</th>\n",
       "      <th>Branch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31462</th>\n",
       "      <td>How Disney can be rated anything other than 5*...</td>\n",
       "      <td>2017-7</td>\n",
       "      <td>Disneyland_Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29019</th>\n",
       "      <td>I have been fortunate enough to be able to vis...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Disneyland_California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18701</th>\n",
       "      <td>Always fun, always clean, always a thrill. The...</td>\n",
       "      <td>2014-7</td>\n",
       "      <td>Disneyland_California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2708</th>\n",
       "      <td>Slightly disappointed during our visit to Disn...</td>\n",
       "      <td>2017-2</td>\n",
       "      <td>Disneyland_HongKong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32737</th>\n",
       "      <td>We booked tickets for Disneyland Paris for a d...</td>\n",
       "      <td>2016-12</td>\n",
       "      <td>Disneyland_Paris</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Review_Text Year_Month  \\\n",
       "31462  How Disney can be rated anything other than 5*...     2017-7   \n",
       "29019  I have been fortunate enough to be able to vis...        NaN   \n",
       "18701  Always fun, always clean, always a thrill. The...     2014-7   \n",
       "2708   Slightly disappointed during our visit to Disn...     2017-2   \n",
       "32737  We booked tickets for Disneyland Paris for a d...    2016-12   \n",
       "\n",
       "                      Branch  \n",
       "31462       Disneyland_Paris  \n",
       "29019  Disneyland_California  \n",
       "18701  Disneyland_California  \n",
       "2708     Disneyland_HongKong  \n",
       "32737       Disneyland_Paris  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1688310487938,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "a9gwDLDAAKAx"
   },
   "outputs": [],
   "source": [
    "# Define function to get statistics about reviews\n",
    "\n",
    "def get_max_mean(reviews):\n",
    "\n",
    "    # Max Number of Words\n",
    "    max_n_words = max([len(review.split()) for review in reviews])\n",
    "\n",
    "    # Mean Number of Words\n",
    "    tot_n_word=0\n",
    "    for review in reviews:\n",
    "        tot_n_word += len(review.split())\n",
    "\n",
    "    mean_n_words = tot_n_word / len(reviews)\n",
    "\n",
    "    return max_n_words, mean_n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 320,
     "status": "ok",
     "timestamp": 1688310488251,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "umCCTk6uALp4",
    "outputId": "8602b9ba-49c0-4b84-cfd4-06a1510d5842"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_n_words: 130.45\n",
      "max_n_words: 3278\n"
     ]
    }
   ],
   "source": [
    "# Review_Text Statistics\n",
    "max_n_words, mean_n_words = get_max_mean(X['Review_Text'])\n",
    "\n",
    "print(f\"mean_n_words: {round(mean_n_words, 2)}\")\n",
    "print(f\"max_n_words: {max_n_words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ad2pS2JVD05P"
   },
   "source": [
    "- **How to (possibly) process/transform each field used?**\n",
    "\n",
    "\n",
    "**Text:**\n",
    "\n",
    "1. Lowercasing: Convert all words to lowercase to ensure consistency and avoid duplication based on case sensitivity.\n",
    "2. Handling Contractions: Expand or resolve contractions and abbreviated forms of words to maintain standardization and improve text understanding.\n",
    "3. Removal of Punctuation: Delete punctuation marks from the text to focus on the actual words and reduce noise.\n",
    "4. Stop Word Removal: Eliminate common words, known as stop words, from the text as they often carry little semantic meaning and can be safely disregarded.\n",
    "\n",
    "After analyzing the textual data and plotting the most frequent words in the reviews, it is advisable to remove the following words:\n",
    "\n",
    "- Words that appear frequently: These words may not contribute much to the predictive power as they are likely generic terms.\n",
    "- Words that appear only once: These words are not likely to provide meaningful insights due to their infrequency.\n",
    "- Words composed of two letters or less: Such short words are often prepositions or conjunctions that don't carry substantial semantic value.\n",
    "- Words that do not belong to the English vocabulary: Removing non-English words ensures the focus remains on relevant terms within the given context.\n",
    "\n",
    "**Branch:**\n",
    "Apply one-hot encoding to represent the \"Branch\" feature as a three-dimensional vector. Afterwards, drop the first column to reduce the dimensionality while preserving the necessary information.\n",
    "\n",
    "**Year_Month:**\n",
    "\n",
    "1. SimpleImputer(strategy='most_frequent'): Fill any missing values in the \"Year_Month\" feature using the most frequent value, ensuring completeness of the dataset.\n",
    "2. Split in two columns: Split the \"Year_Month\" feature into two separate columns, namely \"Year\" and \"Month,\" to facilitate temporal analysis.\n",
    "3. Apply normalization: Normalize the \"Year\" and \"Month\" columns using an appropriate scaling technique to bring the values within a specific range and ensure uniformity for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1688310488251,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "KpfAY48oAul7"
   },
   "outputs": [],
   "source": [
    "# Lowercasing\n",
    "REVIEWS = [review.lower() for review in X['Review_Text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 682,
     "status": "ok",
     "timestamp": 1688310488929,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "FOkwuISHAv0r"
   },
   "outputs": [],
   "source": [
    "# Handling Contractions\n",
    "REVIEWS = [contractions.fix(review) for review in REVIEWS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 338,
     "status": "ok",
     "timestamp": 1688310489265,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "XIS31ZPQAw8M"
   },
   "outputs": [],
   "source": [
    "# Removal of punctuation\n",
    "def remove_punctuation(text):\n",
    "    no_punct = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    return no_punct\n",
    "\n",
    "REVIEWS = [remove_punctuation(review) for review in REVIEWS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 15568,
     "status": "ok",
     "timestamp": 1688310504830,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "WmX-uWhrAx-5"
   },
   "outputs": [],
   "source": [
    "## Stop word removal\n",
    "def remove_stopwords(sentence):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = word_tokenize(sentence)\n",
    "    filtered_tokens = [word for word in tokens if word.casefold() not in stop_words]\n",
    "    filtered_sentence = ' '.join(filtered_tokens)\n",
    "    return filtered_sentence\n",
    "\n",
    "REVIEWS = [remove_stopwords(review) for review in REVIEWS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1688310504831,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "uDMpVRLIA4VN",
    "outputId": "c232bfda-7087-437f-9e72-8bd992136e47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_n_words: 65.99\n",
      "max_n_words: 1557\n"
     ]
    }
   ],
   "source": [
    "# Reviews Statistics\n",
    "max_n_words, mean_n_words = get_max_mean(REVIEWS)\n",
    "\n",
    "print(f\"mean_n_words: {round(mean_n_words, 2)}\")\n",
    "print(f\"max_n_words: {max_n_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 500,
     "status": "ok",
     "timestamp": 1688310505325,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "fLyXRSqQA7xw"
   },
   "outputs": [],
   "source": [
    "# Word count\n",
    "word_counter = Counter()\n",
    "\n",
    "# Iterate over each sentence and update the word counts\n",
    "for review in REVIEWS:\n",
    "    words = review.split()\n",
    "    word_counter.update(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 337,
     "status": "ok",
     "timestamp": 1688310509149,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "idq-OGYoA-Gc"
   },
   "outputs": [],
   "source": [
    "# Sort the word_counter in decreasing order by count\n",
    "SORTED_COUNTS = sorted(word_counter.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Separate the words and counts into separate lists\n",
    "words = [word for word, count in SORTED_COUNTS]\n",
    "counts = [count for word, count in SORTED_COUNTS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 626
    },
    "executionInfo": {
     "elapsed": 916,
     "status": "ok",
     "timestamp": 1688310511272,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "TiDVGBu8BEET",
    "outputId": "d94f1aff-0600-4aa9-b3dc-904a516ab82f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the word counts in a bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(words[:20], counts[:20])\n",
    "\n",
    "plt.xlabel('Words')\n",
    "plt.ylabel('Counts')\n",
    "plt.title('Word Counts')\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 439,
     "status": "ok",
     "timestamp": 1688310513173,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "_ZniuLy6BMcC",
    "outputId": "bb376f5d-74d1-4486-d3b3-9c30d75acfd0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27415, 8605)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = enchant.Dict(\"en_US\")\n",
    "filtered_word_counts = []\n",
    "\n",
    "# Words that appear more than once\n",
    "filtered_word_counts = [(word, count) for word, count in SORTED_COUNTS if count > 1]\n",
    "\n",
    "# Words with more than 2 characters\n",
    "filtered_word_counts = [(word, count) for word, count in filtered_word_counts if len(word) > 2]\n",
    "\n",
    "# Words which are in the english vocabulary\n",
    "filtered_word_counts = [(word, count) for word, count in filtered_word_counts if dictionary.check(word)]\n",
    "\n",
    "len(SORTED_COUNTS), len(filtered_word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 407,
     "status": "ok",
     "timestamp": 1688310514692,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "EYnmyY-kCwdF",
    "outputId": "2dfa4682-0195-45f1-a67a-84b69fc111db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(most_freq_words) = 4\n",
      "len(unique_words) = 15995\n",
      "len(short_words) = 370\n",
      "len(non_english_words) = 14248\n",
      "\n",
      "Total unique words = 27415\n",
      "len(useless_words) = 18812\n",
      "\n",
      "Remaining words after processing = 8603\n"
     ]
    }
   ],
   "source": [
    "most_freq_words = ['park', 'disney', 'rides', 'disneyland']\n",
    "unique_words = [word for word,count in SORTED_COUNTS if count == 1]\n",
    "short_words = [word for word, count in SORTED_COUNTS if len(word) <= 2]\n",
    "non_english_words = [word for word,count in SORTED_COUNTS if not dictionary.check(word)]\n",
    "\n",
    "\n",
    "words_to_remove = []\n",
    "words_to_remove.extend(most_freq_words)\n",
    "words_to_remove.extend(unique_words)\n",
    "words_to_remove.extend(short_words)\n",
    "words_to_remove.extend(non_english_words)\n",
    "words_to_remove = set(words_to_remove)\n",
    "\n",
    "print(f\"len(most_freq_words) = {len(most_freq_words)}\")\n",
    "print(f\"len(unique_words) = {len(unique_words)}\")\n",
    "print(f\"len(short_words) = {len(short_words)}\")\n",
    "print(f\"len(non_english_words) = {len(non_english_words)}\\n\")\n",
    "\n",
    "print(f\"Total unique words = {len(SORTED_COUNTS)}\")\n",
    "print(f\"len(useless_words) = {len(words_to_remove)}\\n\")\n",
    "\n",
    "print(f\"Remaining words after processing = {len(SORTED_COUNTS) - len(words_to_remove)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 460,
     "status": "ok",
     "timestamp": 1688310517250,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "pViY19wvCwzH"
   },
   "outputs": [],
   "source": [
    "filtered_reviews = []\n",
    "\n",
    "for r in REVIEWS:\n",
    "    filtered_review = []\n",
    "    words = r.split()\n",
    "    for w in words:\n",
    "        if w in words_to_remove:\n",
    "            continue\n",
    "        filtered_review.append(w)\n",
    "\n",
    "    filtered_review = \" \".join(filtered_review)\n",
    "    filtered_reviews.append(filtered_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 403,
     "status": "ok",
     "timestamp": 1688310520064,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "jIEnZKskCysb",
    "outputId": "228540c3-6593-40d6-de51-c6753bae745d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_n_words: 54.44\n",
      "max_n_words: 1239\n"
     ]
    }
   ],
   "source": [
    "# Filtered Reviews Statistics\n",
    "max_n_words, mean_n_words = get_max_mean(filtered_reviews)\n",
    "\n",
    "print(f\"mean_n_words: {round(mean_n_words, 2)}\")\n",
    "print(f\"max_n_words: {max_n_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    " #cut reviews at 60 words\n",
    "cut_reviews = []\n",
    "\n",
    "MAX_LENGTH = 60\n",
    "\n",
    "for r in filtered_reviews:\n",
    "    LENGTH = len(r.split())\n",
    "\n",
    "    if LENGTH > MAX_LENGTH:\n",
    "        r = \" \".join(r.split()[:MAX_LENGTH])\n",
    "        cut_reviews.append(r)\n",
    "        continue\n",
    "\n",
    "    if LENGTH < 60:\n",
    "        r = r.split() + [\"<UNK>\"] * (MAX_LENGTH - LENGTH)\n",
    "        cut_reviews.append(\" \".join(r))\n",
    "        continue\n",
    "\n",
    "    else:\n",
    "        cut_reviews.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rated anything beyond magical exciting fun something new unexpected around every corner new shows parades different seasons along different characters meet every day keep fresh new extra magic hours perfection option take advantage bit quieter definitely extra special wait til saved enough pennies place <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK>'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut_reviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 452,
     "status": "ok",
     "timestamp": 1688310751511,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "Hu33nhRJC2pK"
   },
   "outputs": [],
   "source": [
    "def compute_co_occurrence_matrix(reviews, window_size):\n",
    "    co_occurrence_matrix = defaultdict(int)\n",
    "\n",
    "    for review in reviews:\n",
    "\n",
    "        words = review.split()\n",
    "\n",
    "        for i, word in enumerate(words):\n",
    "\n",
    "            start = max(0, i - window_size + 1)\n",
    "            end = min(len(words), i + window_size + 1)\n",
    "\n",
    "            context_words = words[start:end]\n",
    "\n",
    "            for context_word in context_words:\n",
    "\n",
    "                if context_word != word:\n",
    "                    co_occurrence_matrix[(word, context_word)] += 1\n",
    "                else:\n",
    "                    co_occurrence_matrix[(word, context_word)] += 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    word_list = sorted(set(word for word, _ in co_occurrence_matrix.keys()))\n",
    "    num_words = len(word_list)\n",
    "\n",
    "    co_occurrence_array = (np.zeros((num_words, num_words), dtype=np.int32))\n",
    "\n",
    "    for (word, context_word), count in co_occurrence_matrix.items():\n",
    "\n",
    "        i = word_list.index(word)\n",
    "        j = word_list.index(context_word)\n",
    "\n",
    "        co_occurrence_array[i,j] = count\n",
    "\n",
    "\n",
    "    # modify \"<UNK>\" vals\n",
    "    i = word_list.index('<UNK>')\n",
    "    co_occurrence_array[:, i] = np.zeros(co_occurrence_array[:, i].shape)\n",
    "    co_occurrence_array[i, :] = np.zeros(co_occurrence_array[i, :].shape)\n",
    "\n",
    "    return co_occurrence_array, word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 320,
     "status": "ok",
     "timestamp": 1688310755569,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "QmN0hn73C4OK"
   },
   "outputs": [],
   "source": [
    "#co_occurrence_array, word_list = compute_co_occurrence_matrix(cut_reviews, window_size=3)\n",
    "#co_occurrence_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1688310756003,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "4vMNIxYEC6fO"
   },
   "outputs": [],
   "source": [
    "#co_occurrence_array = co_occurrence_array.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1688310756503,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "zFEqGIItC8YH"
   },
   "outputs": [],
   "source": [
    "# Save co-occurrence matrix\n",
    "#np.save('co_occurrence_matrix.npy', co_occurrence_array)\n",
    "#np.save('word_list.npy', word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1688310757326,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "Im3mXOtKC-cc"
   },
   "outputs": [],
   "source": [
    "co_occurrence_matrix = np.load('co_occurrence_matrix.npy')\n",
    "word_list = np.load('word_list.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1688310759350,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "32hZ9PoyDBG3"
   },
   "outputs": [],
   "source": [
    "# pca 100 dimensions\n",
    "#n_components = 100\n",
    "#pca = PCA(n_components=n_components)\n",
    "#co_occurrence_100d = pca.fit_transform(co_occurrence_matrix)\n",
    "\n",
    "# pca 200 dimensions\n",
    "#n_components = 200\n",
    "#pca = PCA(n_components=n_components)\n",
    "#co_occurrence_200d = pca.fit_transform(co_occurrence_matrix)\n",
    "\n",
    "# pca 300 dimensions\n",
    "#n_components = 300\n",
    "#pca = PCA(n_components=n_components)\n",
    "#co_occurrence_300d = pca.fit_transform(co_occurrence_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7060,
     "status": "ok",
     "timestamp": 1688310776356,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "xHr8jjY8uQ84",
    "outputId": "c9395d7b-3aab-4823-ee5b-a13c0976282b"
   },
   "outputs": [],
   "source": [
    "# co_occurrence_matrix and its reductions are computed a priori. I'm exporting them from my github to save time.\n",
    "#!git clone https://github.com/andrealolli13/DeepLearning.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1688310776357,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "k_sIXOgSDEIV",
    "outputId": "1f44ac3e-6619-4b05-ffed-b3c00e510203"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8065, 100) (8065, 200) (8065, 300)\n"
     ]
    }
   ],
   "source": [
    "# Save co-occurrence_reduced matrix\n",
    "#np.save('co_occurrence_100d.npy', co_occurrence_100d)\n",
    "#np.save('co_occurrence_200d.npy', co_occurrence_200d)\n",
    "#np.save('co_occurrence_300d.npy', co_occurrence_300d)\n",
    "#\n",
    "co_occurrence_100d = np.load('co_occurrence_100d.npy')\n",
    "co_occurrence_200d = np.load('co_occurrence_200d.npy')\n",
    "co_occurrence_300d = np.load('co_occurrence_300d.npy')\n",
    "\n",
    "\n",
    "# Check the shape of the reduced matrix\n",
    "print(co_occurrence_100d.shape, co_occurrence_200d.shape, co_occurrence_300d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 379,
     "status": "ok",
     "timestamp": 1688310809739,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "xniDAW1YDHxZ"
   },
   "outputs": [],
   "source": [
    "## Word to int\n",
    "word_list = np.load('word_list.npy')\n",
    "str_to_int = {w:i for i, w in enumerate(word_list)}\n",
    "int_to_str = {i:w for i, w in enumerate(word_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 520,
     "status": "ok",
     "timestamp": 1688310810661,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "e1DcFBbODOME"
   },
   "outputs": [],
   "source": [
    "# Tokenization process\n",
    "ENCODED_REVIEWS = []\n",
    "\n",
    "for r in cut_reviews:\n",
    "    words = r.split()\n",
    "    for i, w in enumerate(words, 0):\n",
    "        number = str_to_int[w]\n",
    "        words[i] = number\n",
    "    enc_rev = words\n",
    "    ENCODED_REVIEWS.append(enc_rev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Year_Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in 'Year_Month': 530\n",
      "Missing values in 'Year_Month' after imputation: 0\n"
     ]
    }
   ],
   "source": [
    "year_month = X['Year_Month']\n",
    "print(f\"Missing values in 'Year_Month': {year_month.isnull().sum()}\")\n",
    "\n",
    "# Fix Missing values\n",
    "si = SimpleImputer(strategy='most_frequent')\n",
    "year_month = si.fit_transform(year_month.to_numpy().reshape(-1, 1))\n",
    "year_month = pd.Series(year_month.flatten())\n",
    "\n",
    "print(f\"Missing values in 'Year_Month' after imputation: {year_month.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(year), len(month): (8532, 8532)\n"
     ]
    }
   ],
   "source": [
    "# Split feature in year, month\n",
    "year = np.array([date.split('-')[0] for date in year_month]).astype('float')\n",
    "month = np.array([date.split('-')[1] for date in year_month]).astype('float')\n",
    "\n",
    "print(f\"len(year), len(month): {len(year), len(month)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "def normalize(array):\n",
    "    \n",
    "    maximum = max(array)\n",
    "    minimum = min(array)\n",
    "    \n",
    "    array = (array - minimum)/(maximum - minimum)\n",
    "    \n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(year_mm), len(month_mm): (8532, 8532)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7777777777777778"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.5454545454545454"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "year_mm = normalize(year)\n",
    "month_mm = normalize(month)\n",
    "\n",
    "print(f\"len(year_mm), len(month_mm): {len(year_mm), len(month_mm)}\")\n",
    "display(year_mm[0], month_mm[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "branch_encoded.columns: Index(['Disneyland_California', 'Disneyland_HongKong', 'Disneyland_Paris'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Disneyland_California</th>\n",
       "      <th>Disneyland_HongKong</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31462</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29019</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18701</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2708</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32737</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27421</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41587</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31950</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13487</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3469</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8532 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Disneyland_California  Disneyland_HongKong\n",
       "31462                      0                    0\n",
       "29019                      1                    0\n",
       "18701                      1                    0\n",
       "2708                       0                    1\n",
       "32737                      0                    0\n",
       "...                      ...                  ...\n",
       "27421                      1                    0\n",
       "41587                      0                    0\n",
       "31950                      0                    0\n",
       "13487                      1                    0\n",
       "3469                       0                    1\n",
       "\n",
       "[8532 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "branch = X['Branch']\n",
    "branch\n",
    "\n",
    "# Perform one-hot encoding\n",
    "branch_encoded = pd.get_dummies(branch)\n",
    "print(f\"branch_encoded.columns: {branch_encoded.columns}\")\n",
    "# drop first\n",
    "branch = branch_encoded[['Disneyland_California', 'Disneyland_HongKong']]\n",
    "branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "branch_list = [list(ohe) for ohe in branch.values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(ENCODED_REVIEWS): <class 'list'>\n",
      "type(year_mm): <class 'numpy.ndarray'>\n",
      "type(month_mm): <class 'numpy.ndarray'>\n",
      "type(branch): <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(f\"type(ENCODED_REVIEWS): {type(ENCODED_REVIEWS)}\")\n",
    "print(f\"type(year_mm): {type(year_mm)}\")\n",
    "print(f\"type(month_mm): {type(month_mm)}\")\n",
    "print(f\"type(branch): {type(branch)}\")\n",
    "\n",
    "# transform \n",
    "## ENCODED_REVIEWS --> numpy.ndarray\n",
    "## branch_list --> numpy.ndarray\n",
    "reviews = np.array(ENCODED_REVIEWS)\n",
    "branch = np.array(branch_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reviews.shape: (8532, 60)\n",
      "year_mm.shape: (8532,)\n",
      "month_mm.shape: (8532,)\n",
      "branch.shape: (8532, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"reviews.shape: {reviews.shape}\")\n",
    "print(f\"year_mm.shape: {year_mm.shape}\")\n",
    "print(f\"month_mm.shape: {month_mm.shape}\")\n",
    "print(f\"branch.shape: {branch.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(len(reviews) == len(branch) == len(year_mm) == len(month_mm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8532, 64)\n"
     ]
    }
   ],
   "source": [
    "# Combine the arrays\n",
    "combined_array = np.concatenate((reviews, year_mm[:, np.newaxis], month_mm[:, np.newaxis], branch), axis=1)\n",
    "\n",
    "# Print the shape of the combined array\n",
    "print(combined_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.77777778, 0.54545455, 0.        , 0.        ])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7777777777777778"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.5454545454545454"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0], dtype=uint8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(combined_array[0][60:], year_mm[0], month_mm[0], branch[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **What is the input of the model, and how is it represented?**\n",
    "\n",
    "**Model input**: The model takes two main inputs: the reviews and the additional features (i.e., \"Year_Month\" and \"Branch\").\n",
    "\n",
    "**Review Input Representation**: To prepare the reviews for the model, several preprocessing steps are applied, including lowercasing, handling contractions, punctuation removal, and stop word removal. After preprocessing, each word in the reviews is assigned a unique integer value based on the vocabulary extracted from our dataset. This integer mapping allows the reviews to be represented as sequences of integers, where each integer corresponds to a specific word in the vocabulary. This representation enables the model to process and analyze the textual data effectively.\n",
    "\n",
    "**Additional Features Representation**:\n",
    "- **Year_Month**: For the \"Year_Month\" feature, any missing values are filled using imputation techniques such as filling with the most frequent value or using forward/backward filling to maintain data completeness.\n",
    "- **Branch**: The \"Branch\" feature is transformed into a one-hot encoded representation, where each branch is represented as a binary vector. This encoding captures the presence or absence of each branch, allowing the model to learn from this categorical information.\n",
    "\n",
    "To incorporate these additional features into the model, their representations are concatenated with the review representations before being passed through the subsequent layers of the model. This way, the model can simultaneously learn from both the reviews and the additional features, leveraging the combined information to make predictions.\n",
    "\n",
    "Please note that the specific implementation details may vary depending on the framework or library used, but the general concept of representing the inputs and incorporating the additional features into the model remains the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "executionInfo": {
     "elapsed": 416,
     "status": "ok",
     "timestamp": 1688310812552,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "7cZIW-neDRwq"
   },
   "outputs": [],
   "source": [
    "# Transform label from integer to vector representation.\n",
    "y_shifted = y - 1\n",
    "num_classes = len(y_shifted.unique())\n",
    "label = to_categorical(y_shifted, num_classes=num_classes)\n",
    "\n",
    "label = [list(r) for r in label]\n",
    "data = list(combined_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8532, 64), (8532, 5))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array(data)\n",
    "label = np.array(label)\n",
    "\n",
    "data.shape, label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "maMGnPzlKWH3"
   },
   "source": [
    "# 2) How would you design the output layer?\n",
    "The output layer should have multiple neurons, equal to the number of classes (e.g., 5 neurons for 5-star ratings). Each neuron will represent the probability or confidence score for each class.\n",
    "A suitable activation function for the output layer in this case is softmax, which normalizes the outputs to represent probabilities across the classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S1exhdmfRR3X"
   },
   "source": [
    "# 3) Which activation functions and which Loss function would you use?\n",
    "ReLU or other nonlinear activation functions can be used for hidden layers to introduce non-linearity.\n",
    "Since it is a multiclass classification problem, the categorical cross-entropy loss function is commonly used. It measures the dissimilarity between predicted probabilities and true class labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NNKkTQu5QQ0L"
   },
   "source": [
    "# 4) Which (possible)  Regularizers, Initializers, Normalizers, etc., and why?\n",
    "Regularization techniques like L1, L2 regularization can still be applied to prevent overfitting and improve generalization. Also a dropout technique can be applied to teach the model to generalize more on the given data.\n",
    "Weight initialization techniques like Xavier or He initialization can be used to ensure stable training.\n",
    "Batch normalization can be beneficial in normalizing activations and accelerating training.\n",
    "As Optimizer Adam (Adaptive Moment Estimation) is a popular optimization algorithm that adapts the learning rate for each parameter based on the estimates of both the first and second moments of the gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "executionInfo": {
     "elapsed": 346,
     "status": "ok",
     "timestamp": 1688310824310,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "ILDQTFpUDffV"
   },
   "outputs": [],
   "source": [
    "def create_model(gru_hid_1, n_hid_1, n_hid_2,\n",
    "                 input_shape=None,\n",
    "                 output_shape=None,\n",
    "                 input_length=None,\n",
    "                 embedding_matrix=None,\n",
    "                 learning_rate=10**-1,\n",
    "                 loss='categorical_crossentropy',\n",
    "                 rnn_act='tanh',\n",
    "                 hid_act='relu',\n",
    "                 out_act='softmax',\n",
    "                 dropout_rate=0.1,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 kernel_regularizer='l1',\n",
    "                 optimizer='adam'):\n",
    "\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    reviews = Lambda(lambda x: x[:, :61])(input_layer)\n",
    "    part_2 = Lambda(lambda x: x[:, 61:])(input_layer)\n",
    "\n",
    "    # Model instantiation\n",
    "    embedding = Embedding(input_dim=embedding_matrix.shape[0],  # Replace with the correct value\n",
    "                          output_dim=embedding_matrix.shape[1],  # Replace with the correct value\n",
    "                          weights=[embedding_matrix],\n",
    "                          input_length=input_length,\n",
    "                          trainable=False)(reviews)\n",
    "    \n",
    "    rnn = GRU(\n",
    "        units=gru_hid_1,\n",
    "        activation=rnn_act,\n",
    "        kernel_initializer=kernel_initializer,\n",
    "        kernel_regularizer=kernel_regularizer,\n",
    "        dropout=dropout_rate,\n",
    "        return_sequences=True\n",
    "    )(embedding)\n",
    "    \n",
    "\n",
    "    concat = Concatenate()([flatten, part_2])  # Concatenate flatten and part_2 inputs\n",
    "\n",
    "    dense_1 = Dense(\n",
    "        units=n_hid_1,\n",
    "        activation=hid_act,\n",
    "        kernel_initializer=kernel_initializer,\n",
    "        kernel_regularizer=kernel_regularizer\n",
    "    )(concat)\n",
    "    \n",
    "    bn_1 = BatchNormalization()(dense_1)\n",
    "    dropout_1 = Dropout(dropout_rate)(bn_1)\n",
    "\n",
    "    dense_2 = Dense(\n",
    "        units=n_hid_2,\n",
    "        activation=hid_act,\n",
    "        kernel_initializer=kernel_initializer,\n",
    "        kernel_regularizer=kernel_regularizer\n",
    "    )(dropout_1)\n",
    "    bn_2 = BatchNormalization()(dense_2)\n",
    "    dropout_2 = Dropout(dropout_rate)(bn_2)\n",
    "\n",
    "    output_layer = Dense(\n",
    "        units=output_shape,\n",
    "        activation=out_act\n",
    "    )(dropout_2)\n",
    "\n",
    "    # Model instantiation\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    # Model compile\n",
    "    model.compile(\n",
    "        loss=loss,\n",
    "        optimizer=optimizer,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "executionInfo": {
     "elapsed": 358,
     "status": "ok",
     "timestamp": 1688310825315,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "90fLRsCTECxQ"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, label,\n",
    "    test_size=0.2,\n",
    "    shuffle=True,\n",
    "    random_state=42)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "executionInfo": {
     "elapsed": 1748,
     "status": "ok",
     "timestamp": 1688310828370,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "3uEG6E9qEDJC"
   },
   "outputs": [],
   "source": [
    "model = create_model(gru_hid_1=16, n_hid_1=32, n_hid_2=32,\n",
    "                 input_shape=(64,),\n",
    "                 output_shape=5,\n",
    "                 input_length=60,\n",
    "                 embedding_matrix=co_occurrence_100d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45047,
     "status": "ok",
     "timestamp": 1688310874653,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "MacnK9WSEFH7",
    "outputId": "46a336b4-87cc-4a8a-e564-078f6d6bfd94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "171/171 [==============================] - 18s 84ms/step - loss: 13.6961 - accuracy: 0.3568 - val_loss: 7.9057 - val_accuracy: 0.5377\n",
      "Epoch 2/5\n",
      "171/171 [==============================] - 14s 80ms/step - loss: 6.2258 - accuracy: 0.4773 - val_loss: 5.0007 - val_accuracy: 0.5575\n",
      "Epoch 3/5\n",
      "171/171 [==============================] - 15s 86ms/step - loss: 4.4356 - accuracy: 0.5075 - val_loss: 3.8003 - val_accuracy: 0.5524\n",
      "Epoch 4/5\n",
      "171/171 [==============================] - 15s 86ms/step - loss: 3.4434 - accuracy: 0.5258 - val_loss: 3.0409 - val_accuracy: 0.5429\n",
      "Epoch 5/5\n",
      "171/171 [==============================] - 14s 80ms/step - loss: 2.7815 - accuracy: 0.5293 - val_loss: 2.4353 - val_accuracy: 0.5495\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=32, epochs=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IpIxOkmVVHhx"
   },
   "source": [
    "# 5) On which hyperparameters would you perform the model selection (if any), or why you would not perform it.\n",
    "- Unit in NN and RNN layers.\n",
    "- Learning Rate.\n",
    "- Dropout Rate.\n",
    "- Activation Function.\n",
    "- Batch sizes.\n",
    "- Kernel Regularizers.\n",
    "- Kernel Initializers.\n",
    "- Optimizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "executionInfo": {
     "elapsed": 334,
     "status": "ok",
     "timestamp": 1688310888882,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "tz9nyCUtuX8-"
   },
   "outputs": [],
   "source": [
    "model = KerasClassifier(\n",
    "    model=create_model,\n",
    "    gru_hid_1=16, n_hid_1=32, n_hid_2=32,\n",
    "    input_shape=(64,),\n",
    "    output_shape=5,\n",
    "    input_length=60,\n",
    "    embedding_matrix=co_occurrence_300d,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1688310889235,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "8G-SNNIxEGar"
   },
   "outputs": [],
   "source": [
    "# layer units\n",
    "gru_hid_1 = [32, 64]\n",
    "n_hid_1 = [64, 128]\n",
    "n_hid_2 = [32, 64]\n",
    "\n",
    "param_grid = dict(model__gru_hid_1 = gru_hid_1,\n",
    "                  model__n_hid_1 = n_hid_1,\n",
    "                  model__n_hid_2 = n_hid_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 117491,
     "status": "ok",
     "timestamp": 1688311007093,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "7twimWzb46ll",
    "outputId": "ee05ea38-77e3-4fc1-8eef-dfec46eb7a6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 5s 50ms/step - loss: 58.9219 - accuracy: 0.2727\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 5s 61ms/step - loss: 56.7014 - accuracy: 0.1515\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 56.6286 - accuracy: 0.5152\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 54.6573 - accuracy: 0.4242\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 5s 85ms/step - loss: 90.8875 - accuracy: 0.2121\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 6s 87ms/step - loss: 56.5452 - accuracy: 0.1765\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 54.6226 - accuracy: 0.4545\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 52.6035 - accuracy: 0.6970\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 6s 64ms/step - loss: 56.7125 - accuracy: 0.1818\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 5s 86ms/step - loss: 58.9337 - accuracy: 0.1176\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 54.6391 - accuracy: 0.4118\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 87.0956 - accuracy: 0.3939\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 6s 59ms/step - loss: 91.2200 - accuracy: 0.1212\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 54.6771 - accuracy: 0.1818\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 51.0201 - accuracy: 0.5455\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 52.7102 - accuracy: 0.6970\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 53.2273 - accuracy: 0.5294\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 56.6660 - accuracy: 0.3824\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 83.3329 - accuracy: 0.4848\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 49.1333 - accuracy: 0.7273\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 50.9974 - accuracy: 0.6970\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 51.8773 - accuracy: 0.6875Epoch 6/10\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 87.3600 - accuracy: 0.5152\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 52.7136 - accuracy: 0.3030\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 55.3578 - accuracy: 0.5938Epoch 4/10\n",
      "2/2 [==============================] - 6s 100ms/step - loss: 58.3139 - accuracy: 0.2727\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 51.9014 - accuracy: 0.6765\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 55.3234 - accuracy: 0.5882\n",
      "Epoch 4/10\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 49.0864 - accuracy: 0.8788\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 84.0640 - accuracy: 0.5758\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 47.3733 - accuracy: 0.7879\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 51.1619 - accuracy: 0.5152\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 79.5280 - accuracy: 0.7273\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 56.5305 - accuracy: 0.2727\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 50.6766 - accuracy: 0.7647\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 54.2017 - accuracy: 0.5882\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 80.5312 - accuracy: 0.6364\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 54.5732 - accuracy: 0.5625Epoch 5/10\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 47.3610 - accuracy: 0.9394\n",
      "2/2 [==============================] - ETA: 0s - loss: 75.9645 - accuracy: 0.5758Epoch 8/10\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 75.9645 - accuracy: 0.5758\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 49.3720 - accuracy: 0.5152\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 54.5640 - accuracy: 0.5758\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 45.6157 - accuracy: 0.7879\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 49.4958 - accuracy: 0.7941\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 52.8899 - accuracy: 0.6765\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 77.0861 - accuracy: 0.8485\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 43.7952 - accuracy: 0.9091\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 45.5777 - accuracy: 0.9091\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 47.6978 - accuracy: 0.5455\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 72.1762 - accuracy: 0.7576\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 48.6437 - accuracy: 0.7059\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 51.6101 - accuracy: 0.6765\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 52.9145 - accuracy: 0.6364\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 43.7725 - accuracy: 0.9394\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 42.0283 - accuracy: 0.9394\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 73.7074 - accuracy: 0.8485\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 45.8220 - accuracy: 0.7273\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 68.5681 - accuracy: 0.9091\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 50.6001 - accuracy: 0.8235\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 44.1932 - accuracy: 0.6250Epoch 8/10\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 51.1039 - accuracy: 0.7273\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 42.0022 - accuracy: 0.8788\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 47.6202 - accuracy: 0.6765\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 44.1901 - accuracy: 0.6364\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 40.1936 - accuracy: 1.0000\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 70.1064 - accuracy: 0.9697\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 64.9957 - accuracy: 0.9697\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 49.3345 - accuracy: 0.8182\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 49.5319 - accuracy: 0.7353\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 42.3544 - accuracy: 0.8485\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 66.7567 - accuracy: 0.9091\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 46.5531 - accuracy: 0.7647\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 61.5774 - accuracy: 0.8182\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 47.6328 - accuracy: 0.8485\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 48.3703 - accuracy: 0.8235\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 58.1740 - accuracy: 0.9091\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 40.6857 - accuracy: 0.8182\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 63.3965 - accuracy: 0.9394\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 45.5979 - accuracy: 0.7647\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 45.8764 - accuracy: 0.8485\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 47.3943 - accuracy: 0.7647\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 60.0280 - accuracy: 0.9394\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 44.2559 - accuracy: 0.8485\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 42.4985 - accuracy: 0.9394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 989ms/step\n",
      "1/1 [==============================] - 1s 961ms/step\n",
      "1/1 [==============================] - 1s 978ms/step\n",
      "1/1 [==============================] - 1s 981ms/step\n",
      "1/1 [==============================] - 1s 938ms/step\n",
      "1/1 [==============================] - 1s 956ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 1s 941ms/step\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 1s 877ms/step\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 5s 92ms/step - loss: 91.4666 - accuracy: 0.1176\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 87.8078 - accuracy: 0.6765\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 5s 102ms/step - loss: 84.8753 - accuracy: 0.1818\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 84.8909 - accuracy: 0.5882\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 5s 95ms/step - loss: 94.8606 - accuracy: 0.1515\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 5s 103ms/step - loss: 84.8963 - accuracy: 0.2727\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 5s 80ms/step - loss: 94.7177 - accuracy: 0.1765\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 81.3348 - accuracy: 0.5152\n",
      "Epoch 3/10\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 5s 77ms/step - loss: 93.8983 - accuracy: 0.3030\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 82.1101 - accuracy: 0.7647\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 90.9079 - accuracy: 0.4242\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 91.0998 - accuracy: 0.4118\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 81.7785 - accuracy: 0.4848\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 90.3622 - accuracy: 0.5455\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 77.7504 - accuracy: 0.5758\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 79.7009 - accuracy: 0.7353\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 87.6853 - accuracy: 0.4848\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 88.0963 - accuracy: 0.7353\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 86.5846 - accuracy: 0.7576\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 78.2156 - accuracy: 0.6364\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 6s 93ms/step - loss: 84.8914 - accuracy: 0.1176\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 84.2684 - accuracy: 0.6364\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 74.0847 - accuracy: 0.7879\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 77.4402 - accuracy: 0.6471\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 85.2334 - accuracy: 0.7353\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 82.7671 - accuracy: 0.7879\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 81.6974 - accuracy: 0.6471\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 80.8227 - accuracy: 0.7879\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 74.7070 - accuracy: 0.6364\n",
      "Epoch 5/10\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 75.0572 - accuracy: 0.8529\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 70.5016 - accuracy: 0.7273\n",
      "Epoch 8/10\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 82.5239 - accuracy: 0.6765\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 78.9799 - accuracy: 0.8485\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 77.4079 - accuracy: 0.8182\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 78.9830 - accuracy: 0.7941\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 72.8849 - accuracy: 0.9412\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 79.8031 - accuracy: 0.7941\n",
      "Epoch 9/10\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 66.7012 - accuracy: 0.8485\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 71.0425 - accuracy: 0.8788\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 75.3219 - accuracy: 0.9091\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 74.0738 - accuracy: 0.9375Epoch 7/10\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 74.0565 - accuracy: 0.9394\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 76.3422 - accuracy: 0.8529\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 70.9168 - accuracy: 0.9706\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 67.5185 - accuracy: 0.8438Epoch 10/10\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 63.0127 - accuracy: 0.8788\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 67.4994 - accuracy: 0.8182\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 77.2805 - accuracy: 0.8529\n",
      "Epoch 7/10\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 71.5347 - accuracy: 0.9091\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 70.7234 - accuracy: 0.9091\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 74.9984 - accuracy: 0.9062Epoch 9/10\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 73.7886 - accuracy: 0.9118\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 68.8646 - accuracy: 0.8824\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 63.9477 - accuracy: 0.9091\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 59.3399 - accuracy: 0.9091\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 74.9788 - accuracy: 0.8824\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 67.8721 - accuracy: 0.9091\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 60.5389 - accuracy: 0.9091\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 67.2398 - accuracy: 0.9394\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 55.8787 - accuracy: 0.9394\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 71.2694 - accuracy: 0.9706\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 72.9787 - accuracy: 0.8235\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 64.3081 - accuracy: 0.9394\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 57.0327 - accuracy: 0.9091\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 71.1119 - accuracy: 0.9375Epoch 10/10\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 63.9864 - accuracy: 0.9091\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 71.0578 - accuracy: 0.9412\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 69.1169 - accuracy: 0.8824\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 60.7551 - accuracy: 0.9697\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 52.4140 - accuracy: 0.9394\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 53.6331 - accuracy: 0.9697\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 66.8130 - accuracy: 0.9118\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 64.6734 - accuracy: 0.9412\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 6s 61ms/step - loss: 87.3757 - accuracy: 0.2727\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 62.5607 - accuracy: 0.9412\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 83.4896 - accuracy: 0.5758\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 1s 1s/steploss: 80.0266 - accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 80.0014 - accuracy: 0.7576\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 76.3749 - accuracy: 0.8788\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 1s 911ms/steps: 72.8049 - accuracy: 0.8750\n",
      "1/1 [==============================] - 1s 914ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 71ms/step - loss: 72.7870 - accuracy: 0.8485\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 1s 986ms/step\n",
      "1/1 [==============================] - 1s 982ms/step\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 69.1364 - accuracy: 0.9697\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 65.4896 - accuracy: 0.9394\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 61.8832 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 58.4362 - accuracy: 0.9697\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 54.9837 - accuracy: 1.0000\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 1s 942ms/step\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 6s 100ms/step - loss: 134.2361 - accuracy: 0.1176\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 6s 68ms/step - loss: 87.0702 - accuracy: 0.2121\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 6s 117ms/step - loss: 87.1169 - accuracy: 0.2059\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 127.5884 - accuracy: 0.5588\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 83.7467 - accuracy: 0.3636\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 83.8139 - accuracy: 0.6176\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 120.7402 - accuracy: 0.5882\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 6s 148ms/step - loss: 134.2025 - accuracy: 0.0606\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 81.0556 - accuracy: 0.7059\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 80.0413 - accuracy: 0.6970\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 79.0874 - accuracy: 0.6471\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 127.0563 - accuracy: 0.5758\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 76.7062 - accuracy: 0.6364\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 114.0418 - accuracy: 0.7353\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 119.5321 - accuracy: 0.7273\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 76.5873 - accuracy: 0.8235\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 107.6205 - accuracy: 0.8235\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 73.0972 - accuracy: 0.8182\n",
      "Epoch 6/10\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 7s 151ms/step - loss: 134.3428 - accuracy: 0.2727\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 111.9492 - accuracy: 0.8788\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 74.4405 - accuracy: 0.7647\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 69.5657 - accuracy: 0.9394\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 101.7771 - accuracy: 0.9118\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 127.5946 - accuracy: 0.5758\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 104.4211 - accuracy: 0.8788\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 178ms/step - loss: 72.3841 - accuracy: 0.9412\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 66.1648 - accuracy: 0.8182\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 166ms/step - loss: 120.3758 - accuracy: 0.7576\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 96.4923 - accuracy: 0.8529\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 7s 101ms/step - loss: 137.6352 - accuracy: 0.2727\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 97.0705 - accuracy: 0.8485\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 70.4737 - accuracy: 0.8529\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 62.5558 - accuracy: 0.9697\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 131.0746 - accuracy: 0.5758\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 113.1894 - accuracy: 0.7576\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 68.7417 - accuracy: 0.7941\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 91.5044 - accuracy: 0.8529\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 89.9605 - accuracy: 0.8788\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 123.9464 - accuracy: 0.8788\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 86.8415 - accuracy: 0.9375Epoch 4/10\n",
      "2/2 [==============================] - 0s 165ms/step - loss: 59.1767 - accuracy: 0.9394\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 66.7658 - accuracy: 0.9412\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 105.8156 - accuracy: 0.8788\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 86.7904 - accuracy: 0.9118\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 83.1636 - accuracy: 0.8788\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 55.7807 - accuracy: 1.0000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 116.8920 - accuracy: 0.7879\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 98.6467 - accuracy: 0.8485\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 82.5184 - accuracy: 0.8824\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 76.5954 - accuracy: 0.8788\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 91.6256 - accuracy: 0.9394\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 162ms/step - loss: 109.5821 - accuracy: 0.9091\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 70.3843 - accuracy: 0.9394\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 102.5138 - accuracy: 0.9091\n",
      "2/2 [==============================] - ETA: 0s - loss: 84.8762 - accuracy: 0.9697Epoch 7/10\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 84.8762 - accuracy: 0.9697\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 7s 102ms/step - loss: 136.9560 - accuracy: 0.2647\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 78.3663 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 95.4686 - accuracy: 0.9394\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 130.5325 - accuracy: 0.5588\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 8s 58ms/step - loss: 137.3514 - accuracy: 0.1818\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 72.2430 - accuracy: 0.9394\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 88.6771 - accuracy: 0.9697\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 1s 1s/steploss: 130.6741 - accuracy: 0.5938\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 130.5872 - accuracy: 0.6061\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 124.0159 - accuracy: 0.7059\n",
      "Epoch 4/10\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 82.1441 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 123.2801 - accuracy: 0.6364\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 118.0246 - accuracy: 0.7059\n",
      "Epoch 4/10\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 75.9262 - accuracy: 0.9697\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 112.4166 - accuracy: 0.9706\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 115.8961 - accuracy: 0.7576\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 107.3661 - accuracy: 0.8824\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 108.4580 - accuracy: 0.9394\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 60ms/step - loss: 102.5157 - accuracy: 0.9412\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 101.2460 - accuracy: 0.9697\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 98.1231 - accuracy: 0.8529\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 94.2435 - accuracy: 0.9697\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 94.0303 - accuracy: 0.8824\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 87.3606 - accuracy: 0.9697\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 90.1721 - accuracy: 0.9412\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 80.8029 - accuracy: 0.9697\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 74.4793 - accuracy: 1.0000\n",
      "1/1 [==============================] - 1s 927ms/step\n",
      "1/1 [==============================] - 1s 614ms/step\n",
      "1/1 [==============================] - 1s 602ms/step\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 4s 103ms/step - loss: 84.8210 - accuracy: 0.1600\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 82.1384 - accuracy: 0.4600\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 79.7099 - accuracy: 0.5000\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 77.2661 - accuracy: 0.7000\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 74.6475 - accuracy: 0.7000\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 72.0043 - accuracy: 0.7600\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 69.4098 - accuracy: 0.8000\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 66.4587 - accuracy: 0.8800\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 63.7223 - accuracy: 0.9400\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 60.9502 - accuracy: 0.9200\n",
      "Best: 0.501225 using {'model__gru_hid_1': 64, 'model__n_hid_1': 64, 'model__n_hid_2': 32}\n",
      "0.40196078431372556 \t with: {'model__gru_hid_1': 32, 'model__n_hid_1': 64, 'model__n_hid_2': 32}\n",
      "0.4044117647058824 \t with: {'model__gru_hid_1': 32, 'model__n_hid_1': 64, 'model__n_hid_2': 64}\n",
      "0.35784313725490197 \t with: {'model__gru_hid_1': 32, 'model__n_hid_1': 128, 'model__n_hid_2': 32}\n",
      "0.3406862745098039 \t with: {'model__gru_hid_1': 32, 'model__n_hid_1': 128, 'model__n_hid_2': 64}\n",
      "0.5012254901960784 \t with: {'model__gru_hid_1': 64, 'model__n_hid_1': 64, 'model__n_hid_2': 32}\n",
      "0.400735294117647 \t with: {'model__gru_hid_1': 64, 'model__n_hid_1': 64, 'model__n_hid_2': 64}\n",
      "0.38235294117647056 \t with: {'model__gru_hid_1': 64, 'model__n_hid_1': 128, 'model__n_hid_2': 32}\n",
      "0.48284313725490197 \t with: {'model__gru_hid_1': 64, 'model__n_hid_1': 128, 'model__n_hid_2': 64}\n"
     ]
    }
   ],
   "source": [
    "GS = GridSearchCV(\n",
    "    estimator = model,\n",
    "    param_grid = param_grid,\n",
    "    scoring = 'accuracy',\n",
    "    n_jobs=-1,\n",
    "    cv = 3,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "grid_result = GS.fit(X_train[:50], y_train[:50])\n",
    "\n",
    "# best result\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_,\n",
    "                             grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "# printing results for all combinations\n",
    "for mean, param in zip(means, params):\n",
    "    print(f\"{mean} \\t with: {param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1688311007094,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "Q_ed3VLUqbjZ"
   },
   "outputs": [],
   "source": [
    "model = KerasClassifier(\n",
    "    model=create_model,\n",
    "    gru_hid_1=64, n_hid_1=64, n_hid_2=32,\n",
    "    input_shape=(64,),\n",
    "    output_shape=5,\n",
    "    input_length=60,\n",
    "    embedding_matrix=co_occurrence_300d,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1688311007095,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "iqZo-9GY5wDt"
   },
   "outputs": [],
   "source": [
    "# learning rates\n",
    "lr = [10**-3, 10**-2, 10**-1]\n",
    "\n",
    "param_grid = dict(model__learning_rate= lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68159,
     "status": "ok",
     "timestamp": 1688311075246,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "A2pIc2R-qlgG",
    "outputId": "08589ace-93f3-4a14-811c-730cbac86e64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 5s 86ms/step - loss: 84.9149 - accuracy: 0.1515\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 5s 87ms/step - loss: 84.6860 - accuracy: 0.2537\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 5s 109ms/step - loss: 84.4833 - accuracy: 0.2239\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 6s 106ms/step - loss: 84.5554 - accuracy: 0.2537\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 80.9297 - accuracy: 0.3485\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 81.0373 - accuracy: 0.3881\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 6s 108ms/step - loss: 84.7445 - accuracy: 0.1970\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 6s 118ms/step - loss: 84.4571 - accuracy: 0.3030\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 6s 137ms/step - loss: 84.0628 - accuracy: 0.2537\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 80.7295 - accuracy: 0.4030\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 6s 121ms/step - loss: 84.4930 - accuracy: 0.2239\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 78.1964 - accuracy: 0.4776\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 81.0490 - accuracy: 0.2985\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 77.2044 - accuracy: 0.4848\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 80.8018 - accuracy: 0.2879\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 80.2279 - accuracy: 0.3485\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 77.2008 - accuracy: 0.5373\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 79.9460 - accuracy: 0.4030\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 80.8465 - accuracy: 0.3582\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 75.2747 - accuracy: 0.5821\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 73.7469 - accuracy: 0.6212\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 78.3539 - accuracy: 0.4328\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 73.8182 - accuracy: 0.6866\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 76.7146 - accuracy: 0.4545\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 181ms/step - loss: 77.3545 - accuracy: 0.4394\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 76.4525 - accuracy: 0.3881\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 77.2786 - accuracy: 0.4925\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 72.4998 - accuracy: 0.6866\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 70.5660 - accuracy: 0.7273\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 74.5854 - accuracy: 0.4688Epoch 6/10\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 75.8868 - accuracy: 0.3881\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 70.8735 - accuracy: 0.6418\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 73.2324 - accuracy: 0.5469Epoch 6/10\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 73.4139 - accuracy: 0.5152\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 73.1790 - accuracy: 0.5373\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 73.6776 - accuracy: 0.6212\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 73.8531 - accuracy: 0.5522\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 150ms/step - loss: 70.0005 - accuracy: 0.6418\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 73.4771 - accuracy: 0.5075\n",
      "Epoch 7/10\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 67.7544 - accuracy: 0.6515\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 69.8859 - accuracy: 0.6970\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 68.0289 - accuracy: 0.6866\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 70.0289 - accuracy: 0.5075\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 70.4071 - accuracy: 0.6364\n",
      "3/3 [==============================] - ETA: 0s - loss: 70.6215 - accuracy: 0.7463Epoch 6/10\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 70.6215 - accuracy: 0.7463\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 64.9974 - accuracy: 0.6667\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 67.4360 - accuracy: 0.7313\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 71.1866 - accuracy: 0.6418\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 66.7239 - accuracy: 0.7576\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 65.1931 - accuracy: 0.7910\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 66.9622 - accuracy: 0.5373\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 67.5971 - accuracy: 0.7015\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 64.5128 - accuracy: 0.5938Epoch 7/10\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 67.0079 - accuracy: 0.6970\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 62.3384 - accuracy: 0.6667\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 65.1260 - accuracy: 0.7313\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 69.3399 - accuracy: 0.6119\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 63.8434 - accuracy: 0.6364\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 63.9486 - accuracy: 0.6875Epoch 8/10\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 62.6385 - accuracy: 0.7761\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 63.9377 - accuracy: 0.6716\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 63.6062 - accuracy: 0.7121\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 147ms/step - loss: 64.6559 - accuracy: 0.6866\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 59.7470 - accuracy: 0.6667\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 62.9926 - accuracy: 0.7313\n",
      "Epoch 10/10\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 67.2097 - accuracy: 0.7612\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 60.0769 - accuracy: 0.7910\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 60.9659 - accuracy: 0.6716\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 60.8772 - accuracy: 0.7273\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 60.4921 - accuracy: 0.8030\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 61.8091 - accuracy: 0.7463\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 65.4134 - accuracy: 0.7164\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 60.8440 - accuracy: 0.7612\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 57.3525 - accuracy: 0.6667\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 58.1879 - accuracy: 0.7015\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 58.1755 - accuracy: 0.8030\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 57.6869 - accuracy: 0.7879\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 55.9375 - accuracy: 0.9062Epoch 10/10\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 59.0765 - accuracy: 0.7612\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 187ms/step - loss: 57.6418 - accuracy: 0.8507\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 63.5905 - accuracy: 0.7015\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 55.5961 - accuracy: 0.8636\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 55.7480 - accuracy: 0.7164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 99ms/step - loss: 56.4894 - accuracy: 0.8209\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 55.0649 - accuracy: 0.7879\n",
      "2/2 [==============================] - 1s 20ms/step\n",
      "2/2 [==============================] - 1s 22ms/step\n",
      "2/2 [==============================] - 1s 25ms/step\n",
      "2/2 [==============================] - 1s 17ms/step\n",
      "2/2 [==============================] - 1s 21ms/step\n",
      "2/2 [==============================] - 1s 11ms/step\n",
      "2/2 [==============================] - 1s 8ms/step\n",
      "2/2 [==============================] - 1s 8ms/step\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 3s 39ms/step - loss: 84.7466 - accuracy: 0.1642\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 80.8102 - accuracy: 0.4627\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 77.8697 - accuracy: 0.5522\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 74.8234 - accuracy: 0.6716\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 72.2276 - accuracy: 0.6866\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 69.6377 - accuracy: 0.7463\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 67.2065 - accuracy: 0.7910\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 65.0038 - accuracy: 0.8358\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 62.9203 - accuracy: 0.8358\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 60.7713 - accuracy: 0.8358\n",
      "2/2 [==============================] - 1s 7ms/step\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 4s 106ms/step - loss: 83.8723 - accuracy: 0.2000\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 1s 122ms/step - loss: 79.0376 - accuracy: 0.3700\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 74.4308 - accuracy: 0.3900\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 113ms/step - loss: 70.1653 - accuracy: 0.5100\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 1s 122ms/step - loss: 66.1299 - accuracy: 0.5400\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 62.2114 - accuracy: 0.5800\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 1s 140ms/step - loss: 58.5322 - accuracy: 0.6000\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 1s 149ms/step - loss: 55.0433 - accuracy: 0.6400\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 1s 118ms/step - loss: 51.5187 - accuracy: 0.7000\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 105ms/step - loss: 48.3869 - accuracy: 0.6800\n",
      "Best: 0.352644 using {'model__learning_rate': 0.1}\n",
      "0.24004753416518124 \t with: {'model__learning_rate': 0.001}\n",
      "0.28163992869875226 \t with: {'model__learning_rate': 0.01}\n",
      "0.35264408793820556 \t with: {'model__learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "GS = GridSearchCV(\n",
    "    estimator = model,\n",
    "    param_grid = param_grid,\n",
    "    scoring = 'accuracy',\n",
    "    n_jobs=-1,\n",
    "    cv = 3,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "grid_result = GS.fit(X_train[:100], y_train[:100])\n",
    "\n",
    "# best result\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_,\n",
    "                             grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "# printing results for all combinations\n",
    "for mean, param in zip(means, params):\n",
    "    print(f\"{mean} \\t with: {param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1688311075247,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "UNv5_Rg_qq2N"
   },
   "outputs": [],
   "source": [
    "# dropout rates\n",
    "dropout_rates = [0.0, 0.1 ,0.2, 0.4, 0.6]\n",
    "\n",
    "param_grid = dict(model__dropout_rate=dropout_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 81927,
     "status": "ok",
     "timestamp": 1688311157166,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "AJqtQieusHIR",
    "outputId": "4bb74e29-8f57-4403-910a-ac36807eb7b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 5s 110ms/step - loss: 84.3109 - accuracy: 0.2388\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 5s 111ms/step - loss: 84.6544 - accuracy: 0.1818\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 5s 85ms/step - loss: 84.4520 - accuracy: 0.1940\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 5s 98ms/step - loss: 84.2132 - accuracy: 0.1791\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 80.6880 - accuracy: 0.3134\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 79.8910 - accuracy: 0.5455\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 79.1698 - accuracy: 0.5821\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 6s 128ms/step - loss: 84.2836 - accuracy: 0.2424\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 79.7692 - accuracy: 0.5522\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 6s 112ms/step - loss: 84.5860 - accuracy: 0.1791\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 6s 118ms/step - loss: 84.5058 - accuracy: 0.2090\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 77.7447 - accuracy: 0.2985\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 75.4184 - accuracy: 0.7273\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 6s 125ms/step - loss: 84.7652 - accuracy: 0.2121\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 80.3293 - accuracy: 0.4091\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 75.9066 - accuracy: 0.7015\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 74.6950 - accuracy: 0.7910\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 80.5763 - accuracy: 0.4925\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 74.7838 - accuracy: 0.2985\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 80.4383 - accuracy: 0.4478\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 70.9361 - accuracy: 0.8182\n",
      "3/3 [==============================] - ETA: 0s - loss: 81.5163 - accuracy: 0.3333Epoch 5/10\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 81.5163 - accuracy: 0.3333\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 72.3703 - accuracy: 0.5312Epoch 3/10\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 72.0490 - accuracy: 0.7910\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 77.1337 - accuracy: 0.4848\n",
      "Epoch 5/10\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 67.5095 - accuracy: 0.8438Epoch 4/10\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 71.9315 - accuracy: 0.4478\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 77.1299 - accuracy: 0.4925\n",
      "3/3 [==============================] - ETA: 0s - loss: 70.4773 - accuracy: 0.8657Epoch 4/10\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 70.4773 - accuracy: 0.8657\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 77.0018 - accuracy: 0.5224\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 78.2950 - accuracy: 0.4848\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 66.7657 - accuracy: 0.8485\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 74.0062 - accuracy: 0.6875Epoch 6/10\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 74.1134 - accuracy: 0.6364\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 69.3587 - accuracy: 0.4627\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 73.8085 - accuracy: 0.5672\n",
      "3/3 [==============================] - 0s 176ms/step - loss: 68.2998 - accuracy: 0.8358\n",
      "Epoch 5/10\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 66.2544 - accuracy: 0.8657\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 73.2975 - accuracy: 0.6866\n",
      "Epoch 6/10\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 63.1515 - accuracy: 0.9394\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 167ms/step - loss: 75.1243 - accuracy: 0.5000\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 67.0111 - accuracy: 0.5373\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 64.5099 - accuracy: 0.9104\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 70.8985 - accuracy: 0.6418\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 71.0604 - accuracy: 0.6818\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 69.8523 - accuracy: 0.7164\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 62.3031 - accuracy: 0.9254\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 59.9781 - accuracy: 0.9242\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 61.0234 - accuracy: 0.8955\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 64.7954 - accuracy: 0.5672\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 66.3152 - accuracy: 0.7761\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 72.1630 - accuracy: 0.4848\n",
      "Epoch 7/10\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 68.3487 - accuracy: 0.6269\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 68.3151 - accuracy: 0.7121\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 58.5916 - accuracy: 0.9403\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 57.0400 - accuracy: 0.9394\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 57.8543 - accuracy: 0.9254\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 62.8770 - accuracy: 0.4478\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 65.8222 - accuracy: 0.7463\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 69.3066 - accuracy: 0.5455\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 55.0758 - accuracy: 0.9552\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 63.0440 - accuracy: 0.7313\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 65.9373 - accuracy: 0.7576\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 54.3540 - accuracy: 0.9394\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 66.5392 - accuracy: 0.5909\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 54.8234 - accuracy: 0.9254\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 51.8214 - accuracy: 0.9403\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 63.6395 - accuracy: 0.7879\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 169ms/step - loss: 60.8624 - accuracy: 0.5373\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 59.8115 - accuracy: 0.8060\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 63.4385 - accuracy: 0.7164\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 52.0565 - accuracy: 0.9394\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 49.0900 - accuracy: 0.9552\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 61.4667 - accuracy: 0.7879\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 51.8915 - accuracy: 0.9403\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 63.7890 - accuracy: 0.5455\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 56.8867 - accuracy: 0.7612\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 61.2448 - accuracy: 0.6866\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 61.1844 - accuracy: 0.6970\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 59.4169 - accuracy: 0.8636\n",
      "3/3 [==============================] - 1s 179ms/step - loss: 53.9273 - accuracy: 0.8358\n",
      "3/3 [==============================] - 1s 161ms/step - loss: 58.8170 - accuracy: 0.7612\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 59.0447 - accuracy: 0.6364\n",
      "2/2 [==============================] - 1s 13ms/step\n",
      "2/2 [==============================] - 1s 30ms/step\n",
      "2/2 [==============================] - 1s 13ms/step\n",
      "2/2 [==============================] - 1s 23ms/step\n",
      "2/2 [==============================] - 1s 37ms/step\n",
      "2/2 [==============================] - 1s 15ms/step\n",
      "2/2 [==============================] - 1s 38ms/step\n",
      "2/2 [==============================] - 1s 22ms/step\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 4s 83ms/step - loss: 84.3661 - accuracy: 0.2090\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 80.8381 - accuracy: 0.3731\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 77.7646 - accuracy: 0.4627\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 5s 93ms/step - loss: 84.7941 - accuracy: 0.2424\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 5s 94ms/step - loss: 85.0001 - accuracy: 0.2273\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 74.8432 - accuracy: 0.6418\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 5s 104ms/step - loss: 84.7702 - accuracy: 0.2985\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 82.4563 - accuracy: 0.1364\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 82.1578 - accuracy: 0.1061\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 5s 97ms/step - loss: 85.1431 - accuracy: 0.1493\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 72.3883 - accuracy: 0.5224\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 82.6243 - accuracy: 0.2239\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 80.3409 - accuracy: 0.1515\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 79.2705 - accuracy: 0.1970\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 5s 103ms/step - loss: 85.6680 - accuracy: 0.1642\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 6s 115ms/step - loss: 85.1372 - accuracy: 0.2090\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 81.9711 - accuracy: 0.2687\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 69.9111 - accuracy: 0.5075\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 80.9398 - accuracy: 0.2239\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 78.5001 - accuracy: 0.1818\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 76.5743 - accuracy: 0.2576\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 83.2776 - accuracy: 0.2687\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 83.1598 - accuracy: 0.1493\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 79.4688 - accuracy: 0.2537\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 67.5087 - accuracy: 0.6119\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 78.9892 - accuracy: 0.3582\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 76.6940 - accuracy: 0.1212\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 81.3230 - accuracy: 0.1940\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 74.2165 - accuracy: 0.3182\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 77.0456 - accuracy: 0.2985\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 80.2065 - accuracy: 0.3125Epoch 5/10\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 81.0180 - accuracy: 0.2836\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 65.2543 - accuracy: 0.6418\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 77.6532 - accuracy: 0.2985\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 74.4039 - accuracy: 0.2121\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 79.6116 - accuracy: 0.2687\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 71.7853 - accuracy: 0.3636\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 74.9415 - accuracy: 0.2985\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 79.2217 - accuracy: 0.2090\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 76.0585 - accuracy: 0.2836\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 63.1294 - accuracy: 0.6716\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 73.1499 - accuracy: 0.2121\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 77.9476 - accuracy: 0.2687\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 69.6110 - accuracy: 0.2879\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 73.1485 - accuracy: 0.2388\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 76.6273 - accuracy: 0.3433\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 61.0986 - accuracy: 0.6866\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 74.7356 - accuracy: 0.2985\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 76.5877 - accuracy: 0.2090\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 71.4697 - accuracy: 0.1212\n",
      "Epoch 9/10\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 75.1626 - accuracy: 0.4062Epoch 7/10\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 67.4294 - accuracy: 0.2879\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 71.0991 - accuracy: 0.3284\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 74.8602 - accuracy: 0.3731\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 73.4860 - accuracy: 0.3582\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 74.8573 - accuracy: 0.2985\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 70.2131 - accuracy: 0.2273\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 65.2036 - accuracy: 0.3333\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 73.5151 - accuracy: 0.1940\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 69.2066 - accuracy: 0.3731\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 72.0858 - accuracy: 0.3881\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 68.6285 - accuracy: 0.2879\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 73.8360 - accuracy: 0.2687\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 63.2074 - accuracy: 0.3485\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 71.7470 - accuracy: 0.2985\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 67.5004 - accuracy: 0.3881\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 70.7871 - accuracy: 0.2836\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 72.4977 - accuracy: 0.2537\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 1s 30ms/stepss: 70.2127 - accuracy: 0.2588\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 70.1691 - accuracy: 0.2388\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 65.9704 - accuracy: 0.4478\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 70.9278 - accuracy: 0.2687\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 68.3460 - accuracy: 0.1493\n",
      "2/2 [==============================] - 1s 11ms/step\n",
      "2/2 [==============================] - 1s 11ms/step\n",
      "2/2 [==============================] - 1s 10ms/step\n",
      "2/2 [==============================] - 1s 11ms/step\n",
      "2/2 [==============================] - 1s 9ms/step\n",
      "2/2 [==============================] - 1s 9ms/step\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 4s 109ms/step - loss: 84.1418 - accuracy: 0.2400\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 110ms/step - loss: 79.5782 - accuracy: 0.3500\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 1s 131ms/step - loss: 75.1633 - accuracy: 0.4800\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 98ms/step - loss: 71.1577 - accuracy: 0.3800\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 1s 171ms/step - loss: 67.0243 - accuracy: 0.5500\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 1s 134ms/step - loss: 63.2915 - accuracy: 0.5400\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 1s 143ms/step - loss: 59.7631 - accuracy: 0.5600\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 100ms/step - loss: 56.4803 - accuracy: 0.6200\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 53.6241 - accuracy: 0.5600\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 1s 121ms/step - loss: 51.0018 - accuracy: 0.5900\n",
      "Best: 0.328580 using {'model__dropout_rate': 0.2}\n",
      "0.29025549613784907 \t with: {'model__dropout_rate': 0.0}\n",
      "0.18894830659536543 \t with: {'model__dropout_rate': 0.1}\n",
      "0.3285799168152109 \t with: {'model__dropout_rate': 0.2}\n",
      "0.220736779560309 \t with: {'model__dropout_rate': 0.4}\n",
      "0.19043374925727866 \t with: {'model__dropout_rate': 0.6}\n"
     ]
    }
   ],
   "source": [
    "GS = GridSearchCV(\n",
    "    estimator = model,\n",
    "    param_grid = param_grid,\n",
    "    scoring = 'accuracy',\n",
    "    n_jobs=-1,\n",
    "    cv = 3,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_result = GS.fit(X_train[:100], y_train[:100])\n",
    "\n",
    "# best result\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_,\n",
    "                             grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "# printing results for all combinations\n",
    "for mean, param in zip(means, params):\n",
    "    print(f\"{mean} \\t with: {param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1688311157167,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "zplJUXqVsI2v"
   },
   "outputs": [],
   "source": [
    "model = KerasClassifier(\n",
    "    model=create_model,\n",
    "    gru_hid_1=64, n_hid_1=64, n_hid_2=32,\n",
    "    dropout_rate=0.2,\n",
    "    input_shape=(64,),\n",
    "    output_shape=5,\n",
    "    input_length=60,\n",
    "    embedding_matrix=co_occurrence_300d,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1688311157168,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "0gtXVn0lswgg"
   },
   "outputs": [],
   "source": [
    "# activation functions\n",
    "activation_functions = ['relu', 'sigmoid', 'tanh']\n",
    "\n",
    "param_grid = dict(model__hid_act=activation_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 106197,
     "status": "ok",
     "timestamp": 1688311263357,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "s0gn3szks-PP",
    "outputId": "5a8ffcbd-5ec4-4e33-a862-2678265eb701"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 7s 127ms/step - loss: 79.4805 - accuracy: 0.1982\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 7s 145ms/step - loss: 80.2907 - accuracy: 0.2613\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 7s 136ms/step - loss: 80.2187 - accuracy: 0.1772\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 8s 170ms/step - loss: 77.2225 - accuracy: 0.3574\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 7s 174ms/step - loss: 78.3359 - accuracy: 0.2222\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 7s 168ms/step - loss: 79.1523 - accuracy: 0.3033\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 8s 148ms/step - loss: 80.3887 - accuracy: 0.2066\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 7s 166ms/step - loss: 78.7362 - accuracy: 0.2994\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 2s 140ms/step - loss: 64.6423 - accuracy: 0.3303\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 143ms/step - loss: 68.1248 - accuracy: 0.3784\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 173ms/step - loss: 68.5356 - accuracy: 0.3213\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 137ms/step - loss: 68.4045 - accuracy: 0.3054\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 168ms/step - loss: 59.4541 - accuracy: 0.4715\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 160ms/step - loss: 64.9638 - accuracy: 0.4114\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 165ms/step - loss: 61.6297 - accuracy: 0.4174\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 140ms/step - loss: 63.4562 - accuracy: 0.3922\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 144ms/step - loss: 50.9457 - accuracy: 0.4354\n",
      " 3/11 [=======>......................] - ETA: 1s - loss: 56.2280 - accuracy: 0.3854Epoch 4/10\n",
      "11/11 [==============================] - 2s 146ms/step - loss: 56.1636 - accuracy: 0.4535\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 161ms/step - loss: 57.5744 - accuracy: 0.3994\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 151ms/step - loss: 57.0105 - accuracy: 0.3832\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 143ms/step - loss: 44.4465 - accuracy: 0.5345\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 152ms/step - loss: 51.9677 - accuracy: 0.4835\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 163ms/step - loss: 46.5887 - accuracy: 0.4985\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 151ms/step - loss: 49.5365 - accuracy: 0.4491\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 141ms/step - loss: 39.2918 - accuracy: 0.5075\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 153ms/step - loss: 45.5517 - accuracy: 0.4835\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 159ms/step - loss: 47.6955 - accuracy: 0.4505\n",
      " 9/11 [=======================>......] - ETA: 0s - loss: 41.1516 - accuracy: 0.6076Epoch 5/10\n",
      "11/11 [==============================] - 2s 151ms/step - loss: 46.6550 - accuracy: 0.4491\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 173ms/step - loss: 33.2193 - accuracy: 0.6066\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 145ms/step - loss: 37.9214 - accuracy: 0.5988\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 150ms/step - loss: 40.5365 - accuracy: 0.5946\n",
      " 6/11 [===============>..............] - ETA: 0s - loss: 38.3131 - accuracy: 0.5990Epoch 5/10\n",
      "11/11 [==============================] - 2s 172ms/step - loss: 34.8617 - accuracy: 0.5736\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 158ms/step - loss: 30.4496 - accuracy: 0.6006\n",
      " 3/11 [=======>......................] - ETA: 1s - loss: 31.8532 - accuracy: 0.6667Epoch 6/10\n",
      "11/11 [==============================] - 2s 175ms/step - loss: 36.8283 - accuracy: 0.6066\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 161ms/step - loss: 39.5227 - accuracy: 0.5315\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 138ms/step - loss: 25.7421 - accuracy: 0.6727\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 149ms/step - loss: 31.7364 - accuracy: 0.6607\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 170ms/step - loss: 38.1877 - accuracy: 0.4551\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 156ms/step - loss: 29.5833 - accuracy: 0.6707\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 135ms/step - loss: 27.0089 - accuracy: 0.6186\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 156ms/step - loss: 24.6134 - accuracy: 0.5946\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 154ms/step - loss: 30.2411 - accuracy: 0.6066\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 158ms/step - loss: 32.8657 - accuracy: 0.6006\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 141ms/step - loss: 31.5576 - accuracy: 0.5599\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 168ms/step - loss: 20.7793 - accuracy: 0.6757\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 158ms/step - loss: 25.6288 - accuracy: 0.7508\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 152ms/step - loss: 21.8458 - accuracy: 0.6276\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 158ms/step - loss: 24.3791 - accuracy: 0.6168\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 167ms/step - loss: 20.9923 - accuracy: 0.6366\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 1s 139ms/step - loss: 25.2720 - accuracy: 0.6517\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 2s 157ms/step - loss: 27.9185 - accuracy: 0.6156\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 2s 164ms/step - loss: 26.0277 - accuracy: 0.6497\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 2s 154ms/step - loss: 17.5769 - accuracy: 0.6967\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 2s 155ms/step - loss: 21.7615 - accuracy: 0.6667\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 2s 147ms/step - loss: 20.6590 - accuracy: 0.6856\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 2s 156ms/step - loss: 18.3744 - accuracy: 0.6246\n",
      " 1/11 [=>............................] - ETA: 1s - loss: 19.7227 - accuracy: 0.7812Epoch 8/10\n",
      "11/11 [==============================] - 2s 176ms/step - loss: 18.1297 - accuracy: 0.6336\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 2s 188ms/step - loss: 21.9531 - accuracy: 0.6126\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 1s 136ms/step - loss: 18.8935 - accuracy: 0.7327\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 2s 150ms/step - loss: 22.0968 - accuracy: 0.6257\n",
      "11/11 [==============================] - 2s 150ms/step - loss: 15.0753 - accuracy: 0.7177\n",
      "Epoch 9/10\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 2s 172ms/step - loss: 24.1945 - accuracy: 0.6456\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 2s 151ms/step - loss: 17.6683 - accuracy: 0.7156\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 2s 170ms/step - loss: 16.0737 - accuracy: 0.6907\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 2s 144ms/step - loss: 16.0370 - accuracy: 0.7147\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 2s 169ms/step - loss: 19.7312 - accuracy: 0.6697\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 2s 139ms/step - loss: 16.6819 - accuracy: 0.7568\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 2s 135ms/step - loss: 15.9706 - accuracy: 0.6527\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 2s 155ms/step - loss: 13.1355 - accuracy: 0.7327\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 2s 147ms/step - loss: 21.3373 - accuracy: 0.6246\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 2s 165ms/step - loss: 19.5334 - accuracy: 0.6377\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 2s 181ms/step - loss: 14.1107 - accuracy: 0.6937\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 2s 142ms/step - loss: 14.2574 - accuracy: 0.7598\n",
      "11/11 [==============================] - 1s 128ms/step - loss: 19.4098 - accuracy: 0.6306\n",
      "11/11 [==============================] - 1s 128ms/step - loss: 14.3821 - accuracy: 0.7365\n",
      "11/11 [==============================] - 2s 159ms/step - loss: 15.0055 - accuracy: 0.7538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 2s 172ms/step - loss: 17.8381 - accuracy: 0.6426\n",
      "11/11 [==============================] - 2s 165ms/step - loss: 11.9313 - accuracy: 0.7267\n",
      "11/11 [==============================] - 2s 151ms/step - loss: 17.8460 - accuracy: 0.6467\n",
      "11/11 [==============================] - 2s 140ms/step - loss: 12.3411 - accuracy: 0.7267\n",
      "6/6 [==============================] - 2s 30ms/step\n",
      "6/6 [==============================] - 1s 28ms/step\n",
      "6/6 [==============================] - 1s 34ms/step\n",
      "6/6 [==============================] - 1s 35ms/step\n",
      "6/6 [==============================] - 1s 19ms/step\n",
      "6/6 [==============================] - 1s 22ms/step\n",
      "6/6 [==============================] - 1s 22ms/step\n",
      "6/6 [==============================] - 1s 15ms/step\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 3s 39ms/step - loss: 79.5099 - accuracy: 0.2246\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 0s 38ms/step - loss: 65.0691 - accuracy: 0.3503\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 0s 38ms/step - loss: 51.4414 - accuracy: 0.4042\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 0s 38ms/step - loss: 39.8291 - accuracy: 0.5120\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 0s 38ms/step - loss: 31.1924 - accuracy: 0.5120\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 0s 37ms/step - loss: 25.1034 - accuracy: 0.5629\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 0s 37ms/step - loss: 20.7144 - accuracy: 0.6796\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 0s 38ms/step - loss: 18.0575 - accuracy: 0.6347\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 0s 38ms/step - loss: 16.0041 - accuracy: 0.6407\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 0s 37ms/step - loss: 14.3165 - accuracy: 0.6886\n",
      "6/6 [==============================] - 1s 12ms/step\n",
      "Epoch 1/10\n",
      "16/16 [==============================] - 6s 130ms/step - loss: 74.9954 - accuracy: 0.2380\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 2s 130ms/step - loss: 51.9231 - accuracy: 0.3520\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 2s 139ms/step - loss: 33.9617 - accuracy: 0.4640\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 2s 128ms/step - loss: 24.0836 - accuracy: 0.5000\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 2s 123ms/step - loss: 18.7970 - accuracy: 0.5500\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 2s 127ms/step - loss: 15.1856 - accuracy: 0.5820\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 2s 112ms/step - loss: 13.1622 - accuracy: 0.5900\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 2s 128ms/step - loss: 11.7614 - accuracy: 0.6340\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 2s 132ms/step - loss: 11.1399 - accuracy: 0.6220\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 2s 113ms/step - loss: 10.0903 - accuracy: 0.7080\n",
      "Best: 0.452024 using {'model__hid_act': 'sigmoid'}\n",
      "0.4339273260707501 \t with: {'model__hid_act': 'relu'}\n",
      "0.4520236635163408 \t with: {'model__hid_act': 'sigmoid'}\n",
      "0.38806723901594403 \t with: {'model__hid_act': 'tanh'}\n"
     ]
    }
   ],
   "source": [
    "GS = GridSearchCV(\n",
    "    estimator = model,\n",
    "    param_grid = param_grid,\n",
    "    scoring = 'accuracy',\n",
    "    n_jobs=-1,\n",
    "    cv = 3,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_result = GS.fit(X_train[:500], y_train[:500])\n",
    "\n",
    "# best result\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_,\n",
    "                             grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "# printing results for all combinations\n",
    "for mean, param in zip(means, params):\n",
    "    print(f\"{mean} \\t with: {param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1688311263358,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "xK1fKHnKtAaM"
   },
   "outputs": [],
   "source": [
    "# batch sizes\n",
    "batch_size = [1, X_train[:100].shape[0], 16, 32]\n",
    "param_grid = dict(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 110483,
     "status": "ok",
     "timestamp": 1688311373832,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "9adED0VmuQLR",
    "outputId": "146a6204-cb30-4788-bb92-eaa3db70017d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 6s 6s/step - loss: 85.2505 - accuracy: 0.2537\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 83.7802 - accuracy: 0.2239\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 6s 133ms/step - loss: 84.1882 - accuracy: 0.2388\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 6s 6s/step - loss: 85.2749 - accuracy: 0.2090\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 6s 146ms/step - loss: 83.7099 - accuracy: 0.2424\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 82.1359 - accuracy: 0.3433\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 83.5761 - accuracy: 0.2985\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 80.5527 - accuracy: 0.4030\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 82.0331 - accuracy: 0.3881\n",
      "Epoch 4/10\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 6s 6s/step - loss: 85.4126 - accuracy: 0.2727\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 80.3883 - accuracy: 0.4328\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 78.9521 - accuracy: 0.3881\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 83.5856 - accuracy: 0.1970\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 78.8961 - accuracy: 0.5224\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 77.3943 - accuracy: 0.4328\n",
      "Epoch 6/10\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 79.0882 - accuracy: 0.2727\n",
      "32/67 [=============>................] - ETA: 2s - loss: 48.8404 - accuracy: 0.3438Epoch 3/10\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 82.2037 - accuracy: 0.2576\n",
      "50/66 [=====================>........] - ETA: 1s - loss: 38.0513 - accuracy: 0.6000Epoch 4/10\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 79.8663 - accuracy: 0.2687\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 77.3598 - accuracy: 0.5970\n",
      "52/66 [======================>.......] - ETA: 0s - loss: 37.1206 - accuracy: 0.5962Epoch 7/10\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 75.8251 - accuracy: 0.4478\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 80.5364 - accuracy: 0.3636\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 75.6964 - accuracy: 0.6119\n",
      "38/67 [================>.............] - ETA: 2s - loss: 44.5306 - accuracy: 0.3947Epoch 8/10\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 78.7844 - accuracy: 0.4697\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 74.0442 - accuracy: 0.5522\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 74.0274 - accuracy: 0.6418\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 77.2589 - accuracy: 0.4848\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 74.5153 - accuracy: 0.4697\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 72.4974 - accuracy: 0.4925\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 75.9170 - accuracy: 0.4627\n",
      "61/66 [==========================>...] - ETA: 0s - loss: 33.4082 - accuracy: 0.5574Epoch 4/10\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 72.4639 - accuracy: 0.6567\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 75.5835 - accuracy: 0.4545\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 70.8593 - accuracy: 0.5821\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 70.8756 - accuracy: 0.6866\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 73.9753 - accuracy: 0.5758\n",
      "Epoch 9/10\n",
      "66/66 [==============================] - 9s 67ms/step - loss: 31.6082 - accuracy: 0.5606\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 72.3288 - accuracy: 0.6212\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 69.9835 - accuracy: 0.5152\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 70.6930 - accuracy: 0.5909\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 71.9778 - accuracy: 0.5373\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 65.4468 - accuracy: 0.5909\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 68.3297 - accuracy: 0.4478\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 10s 68ms/step - loss: 31.3353 - accuracy: 0.5522\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 10s 68ms/step - loss: 31.1723 - accuracy: 0.4478\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 1s 1s/steploss: 65.5358 - accuracy: 0.4688\n",
      "1/1 [==============================] - 2s 2s/steploss: 61.0252 - accuracy: 0.6406\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 60.9816 - accuracy: 0.6364\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 64.7416 - accuracy: 0.4776\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 2s 2s/step- loss: 7.1021 - accuracy: 0.7692\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 56.8185 - accuracy: 0.6515\n",
      "Epoch 8/10\n",
      "20/67 [=======>......................] - ETA: 3s - loss: 6.4128 - accuracy: 0.7500Epoch 1/10\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 61.0341 - accuracy: 0.6567\n",
      "Epoch 8/10\n",
      "3/5 [=================>............] - ETA: 0s - loss: 53.2215 - accuracy: 0.7500Epoch 1/10\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 52.7810 - accuracy: 0.7727\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 57.6702 - accuracy: 0.6269\n",
      "2/5 [===========>..................] - ETA: 0s - loss: 50.0216 - accuracy: 0.7188Epoch 9/10\n",
      "32/67 [=============>................] - ETA: 2s - loss: 5.4810 - accuracy: 0.6562Epoch 1/10\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 49.2699 - accuracy: 0.6818\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 54.5139 - accuracy: 0.6119\n",
      "Epoch 10/10\n",
      "66/66 [==============================] - 4s 64ms/step - loss: 4.1666 - accuracy: 0.5758\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 1s 115ms/step - loss: 46.0918 - accuracy: 0.6667\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 51.3203 - accuracy: 0.6567\n",
      "67/67 [==============================] - 4s 66ms/step - loss: 4.0374 - accuracy: 0.5970\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 4s 66ms/step - loss: 4.0537 - accuracy: 0.5075\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 1s 32ms/steploss: 2.4069 - accuracy: 0.27\n",
      "3/3 [==============================] - 2s 46ms/steploss: 2.2832 - accuracy: 0.44\n",
      "36/67 [===============>..............] - ETA: 1s - loss: 2.1803 - accuracy: 0.4722Epoch 1/10\n",
      "66/66 [==============================] - 4s 57ms/step - loss: 2.0047 - accuracy: 0.5758\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 4s 57ms/step - loss: 1.9562 - accuracy: 0.5970\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 4s 57ms/step - loss: 2.0317 - accuracy: 0.5075\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 8s 103ms/step - loss: 84.4796 - accuracy: 0.1818\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 80.3760 - accuracy: 0.3788\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 9s 119ms/step - loss: 83.5253 - accuracy: 0.1642\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 8s 138ms/step - loss: 84.5951 - accuracy: 0.2537\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 76.9202 - accuracy: 0.3788\n",
      "Epoch 4/10\n",
      "66/66 [==============================] - 4s 56ms/step - loss: 1.6085 - accuracy: 0.5758\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 81.4884 - accuracy: 0.2537\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 73.4871 - accuracy: 0.3788\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 79.3125 - accuracy: 0.4030\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 78.5660 - accuracy: 0.3881\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 70.2974 - accuracy: 0.4394\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 116ms/step - loss: 75.6974 - accuracy: 0.3731\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 75.9137 - accuracy: 0.4328\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 67.8271 - accuracy: 0.4219Epoch 5/10\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 67.7876 - accuracy: 0.4242\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 73.1080 - accuracy: 0.5522\n",
      "61/67 [==========================>...] - ETA: 0s - loss: 1.7108 - accuracy: 0.5082Epoch 6/10\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 65.4216 - accuracy: 0.5455\n",
      "63/67 [===========================>..] - ETA: 0s - loss: 1.7201 - accuracy: 0.4921Epoch 8/10\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 71.7886 - accuracy: 0.4627\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 4s 58ms/step - loss: 1.5784 - accuracy: 0.5970\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 4s 57ms/step - loss: 1.7002 - accuracy: 0.5075\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 70.6720 - accuracy: 0.5075\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 63.3406 - accuracy: 0.5455\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 67.8880 - accuracy: 0.6716\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 61.2999 - accuracy: 0.5000\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 1s 156ms/step - loss: 68.2847 - accuracy: 0.4776\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 65.5967 - accuracy: 0.7313\n",
      "14/67 [=====>........................] - ETA: 3s - loss: 1.6292 - accuracy: 0.5000Epoch 9/10\n",
      "3/3 [==============================] - 1s 176ms/step - loss: 59.1807 - accuracy: 0.6061\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 64.8207 - accuracy: 0.4776\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 63.5082 - accuracy: 0.6866\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 7s 104ms/step - loss: 84.7395 - accuracy: 0.1791\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 61.3925 - accuracy: 0.6716\n",
      "5/5 [==============================] - 1s 107ms/step - loss: 61.4896 - accuracy: 0.5373\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 81.1489 - accuracy: 0.3582\n",
      "Epoch 3/10\n",
      "66/66 [==============================] - 4s 58ms/step - loss: 1.5558 - accuracy: 0.5758\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 78.3642 - accuracy: 0.3582\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 58.0224 - accuracy: 0.5970\n",
      "38/67 [================>.............] - ETA: 1s - loss: 1.5988 - accuracy: 0.5000Epoch 9/10\n",
      "2/2 [==============================] - 1s 26ms/steploss: 1.4945 - accuracy: 0.6000\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 75.7808 - accuracy: 0.3582\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 54.8747 - accuracy: 0.6567\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 73.2038 - accuracy: 0.5821\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 1s 22ms/stepss: 52.7440 - accuracy: 0.68862\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 70.9572 - accuracy: 0.5075\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 52.0348 - accuracy: 0.7313\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 68.8725 - accuracy: 0.5821\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 4s 53ms/step - loss: 1.5021 - accuracy: 0.5970\n",
      "65/67 [============================>.] - ETA: 0s - loss: 1.6245 - accuracy: 0.5231Epoch 6/10\n",
      "67/67 [==============================] - 4s 54ms/step - loss: 1.6368 - accuracy: 0.5075\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 66.9580 - accuracy: 0.5522\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 65.0075 - accuracy: 0.6269\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 62.9236 - accuracy: 0.6567\n",
      "3/3 [==============================] - 1s 25ms/steploss: 1.6500 - accuracy: 0.5716\n",
      "66/66 [==============================] - 3s 42ms/step - loss: 1.5321 - accuracy: 0.5758\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 1s 21ms/steploss: 1.5676 - accuracy: 0.5306\n",
      "67/67 [==============================] - 2s 36ms/step - loss: 1.4876 - accuracy: 0.5970\n",
      "65/67 [============================>.] - ETA: 0s - loss: 1.6455 - accuracy: 0.5077Epoch 7/10\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 1.6453 - accuracy: 0.5075\n",
      "Epoch 7/10\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 1.5186 - accuracy: 0.5758\n",
      "35/67 [==============>...............] - ETA: 1s - loss: 1.5486 - accuracy: 0.5714Epoch 8/10\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 1.4739 - accuracy: 0.5970\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 1.6343 - accuracy: 0.5075\n",
      "33/66 [==============>...............] - ETA: 1s - loss: 1.5347 - accuracy: 0.5455Epoch 8/10\n",
      "66/66 [==============================] - 2s 33ms/step - loss: 1.5044 - accuracy: 0.5758\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 1.4669 - accuracy: 0.5970\n",
      "29/66 [============>.................] - ETA: 1s - loss: 1.5201 - accuracy: 0.5172Epoch 9/10\n",
      "67/67 [==============================] - 2s 36ms/step - loss: 1.6291 - accuracy: 0.5075\n",
      "Epoch 9/10\n",
      "66/66 [==============================] - 2s 35ms/step - loss: 1.5099 - accuracy: 0.5758\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 1.4780 - accuracy: 0.5970\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 1.6165 - accuracy: 0.5075\n",
      "Epoch 10/10\n",
      "66/66 [==============================] - 2s 33ms/step - loss: 1.5090 - accuracy: 0.5758\n",
      "67/67 [==============================] - 2s 30ms/step - loss: 1.4660 - accuracy: 0.5970\n",
      "67/67 [==============================] - 2s 30ms/step - loss: 1.6249 - accuracy: 0.5075\n",
      "34/34 [==============================] - 1s 8ms/step\n",
      "33/33 [==============================] - 1s 7ms/step\n",
      "33/33 [==============================] - 1s 6ms/step\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 8s 56ms/step - loss: 22.6844 - accuracy: 0.4800\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 6s 57ms/step - loss: 2.2222 - accuracy: 0.5600\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 6s 55ms/step - loss: 1.6248 - accuracy: 0.5600\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 1.5581 - accuracy: 0.5600\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 5s 53ms/step - loss: 1.5546 - accuracy: 0.5600\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 5s 52ms/step - loss: 1.5529 - accuracy: 0.5600\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 5s 50ms/step - loss: 1.5497 - accuracy: 0.5600\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 6s 56ms/step - loss: 1.5448 - accuracy: 0.5600\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 6s 57ms/step - loss: 1.5457 - accuracy: 0.5600\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 6s 60ms/step - loss: 1.5442 - accuracy: 0.5600\n",
      "Best: 0.560309 using {'batch_size': 1}\n",
      "0.5603089720736779 \t with: {'batch_size': 1}\n",
      "0.30124777183600715 \t with: {'batch_size': 100}\n",
      "0.20974450386215093 \t with: {'batch_size': 16}\n",
      "0.19102792632204393 \t with: {'batch_size': 32}\n"
     ]
    }
   ],
   "source": [
    "GS = GridSearchCV(\n",
    "    estimator = model,\n",
    "    param_grid = param_grid,\n",
    "    scoring = 'accuracy',\n",
    "    n_jobs=-1,\n",
    "    cv = 3,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_result = GS.fit(X_train[:100], y_train[:100])\n",
    "\n",
    "# best result\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_,\n",
    "                             grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "# printing results for all combinations\n",
    "for mean, param in zip(means, params):\n",
    "    print(f\"{mean} \\t with: {param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "executionInfo": {
     "elapsed": 588,
     "status": "ok",
     "timestamp": 1688311380300,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "c3e8-E2auYBI"
   },
   "outputs": [],
   "source": [
    "model = KerasClassifier(\n",
    "    model=create_model,\n",
    "    gru_hid_1=64, n_hid_1=64, n_hid_2=32,\n",
    "    dropout_rate=0.2,\n",
    "    batch_size=32,\n",
    "    input_shape=(64,),\n",
    "    output_shape=5,\n",
    "    input_length=60,\n",
    "    embedding_matrix=co_occurrence_300d,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1688311380302,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "OAQsYrKsvS74"
   },
   "outputs": [],
   "source": [
    "# kernel regularizer\n",
    "kernel_regularizer = [None, 'l1', 'l2', 'l1_l2']\n",
    "\n",
    "param_grid = dict(model__kernel_regularizer=kernel_regularizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 67854,
     "status": "ok",
     "timestamp": 1688311449524,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "FpmQOYZ8vUlk",
    "outputId": "5431fbe5-73bf-4040-86b1-d220bb8addc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 2s 40ms/step - loss: 2.5685 - accuracy: 0.1970\n",
      "Epoch 2/10\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6486 - accuracy: 0.3438Epoch 1/10\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1.7309 - accuracy: 0.3182\n",
      "Epoch 3/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "1/3 [=========>....................] - ETA: 4s - loss: 2.2610 - accuracy: 0.2188Epoch 1/10\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 1.4460 - accuracy: 0.5000Epoch 1/10\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 1.4700 - accuracy: 0.4848\n",
      "Epoch 4/10\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 2s 61ms/step - loss: 2.1217 - accuracy: 0.2537\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 1.5611 - accuracy: 0.4848\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 1.6900 - accuracy: 0.4328\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 1.1217 - accuracy: 0.5455\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 1.6697 - accuracy: 0.4030\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 1.2334 - accuracy: 0.5606\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 1.6606 - accuracy: 0.3134\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 1.0197 - accuracy: 0.6515\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 1.3822 - accuracy: 0.4776\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.9744 - accuracy: 0.6515\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.1980 - accuracy: 0.5373\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1.0738 - accuracy: 0.6119\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.9737 - accuracy: 0.6667\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.7515 - accuracy: 0.7273\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 1.0816 - accuracy: 0.5075\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 1.0954 - accuracy: 0.5373\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 1.0791 - accuracy: 0.5970\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 3s 31ms/step - loss: 2.3070 - accuracy: 0.1642\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 1.6660 - accuracy: 0.2836\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 3s 43ms/step - loss: 84.6684 - accuracy: 0.2090\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 3s 45ms/step - loss: 6.2549 - accuracy: 0.2239\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 3s 52ms/step - loss: 84.6854 - accuracy: 0.2239\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 1.5292 - accuracy: 0.3582\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 3s 54ms/step - loss: 6.6368 - accuracy: 0.1212\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 84.9446 - accuracy: 0.1875Epoch 2/10\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 81.6065 - accuracy: 0.3582\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 3s 49ms/step - loss: 84.8689 - accuracy: 0.1818\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 5.8882 - accuracy: 0.3125Epoch 2/10\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 5.8954 - accuracy: 0.2985\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 81.2918 - accuracy: 0.3731\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 5.8442 - accuracy: 0.3182\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.3357 - accuracy: 0.4776\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 79.1316 - accuracy: 0.2836\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 80.6178 - accuracy: 0.3636\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 5.6355 - accuracy: 0.2687\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 78.1745 - accuracy: 0.4030\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 76.8802 - accuracy: 0.3750Epoch 4/10\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 5.5073 - accuracy: 0.3939\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 1.2971 - accuracy: 0.5522\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 76.4686 - accuracy: 0.4091\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 76.3769 - accuracy: 0.3881\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 5.4772 - accuracy: 0.2985\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 75.0741 - accuracy: 0.4179\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 5.2236 - accuracy: 0.4848\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 1.0428 - accuracy: 0.6119\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 73.7891 - accuracy: 0.4627\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 73.0279 - accuracy: 0.4545\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 5.5546 - accuracy: 0.2388\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 72.1229 - accuracy: 0.4925\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 5.1624 - accuracy: 0.5152\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.9888 - accuracy: 0.6119\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 71.6671 - accuracy: 0.4328\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 69.3600 - accuracy: 0.4697\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 5.4295 - accuracy: 0.3582\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 69.4636 - accuracy: 0.5075\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.8158 - accuracy: 0.6875Epoch 7/10\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 5.0634 - accuracy: 0.5303\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.9138 - accuracy: 0.6418\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 65.7559 - accuracy: 0.5303\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 69.3700 - accuracy: 0.4179\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 5.3438 - accuracy: 0.4776\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 66.6269 - accuracy: 0.5970\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 4.9188 - accuracy: 0.5303\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 67.1485 - accuracy: 0.5075\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 62.5074 - accuracy: 0.6061\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 1.0177 - accuracy: 0.5522\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 5.2515 - accuracy: 0.4925\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 64.0829 - accuracy: 0.5522\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 65.4398 - accuracy: 0.5000Epoch 9/10\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 4.8619 - accuracy: 0.5758\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.9294 - accuracy: 0.7164\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 59.5417 - accuracy: 0.7424\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 64.9969 - accuracy: 0.5373\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 61.4904 - accuracy: 0.6269\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 5.0587 - accuracy: 0.5522\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 4.7428 - accuracy: 0.6212\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 62.9268 - accuracy: 0.4925\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 59.1865 - accuracy: 0.5373\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 57.0478 - accuracy: 0.5758\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 5.0961 - accuracy: 0.4925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 38ms/step - loss: 4.5933 - accuracy: 0.8182\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 54.6393 - accuracy: 0.6667\n",
      "3/3 [==============================] - 3s 36ms/step - loss: 6.0667 - accuracy: 0.2836\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 5.5684 - accuracy: 0.3433\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 11ms/stepss: 5.2756 - accuracy: 0.6250\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 5.1762 - accuracy: 0.5672\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 5.1866 - accuracy: 0.4925\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 3s 42ms/step - loss: 88.5644 - accuracy: 0.2576\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 6ms/steposs: 5.0520 - accuracy: 0.5312\n",
      "2/2 [==============================] - 1s 30ms/step\n",
      "2/2 [==============================] - 1s 8ms/step\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 5.0021 - accuracy: 0.5522\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 84.9921 - accuracy: 0.3485\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 4.8278 - accuracy: 0.6119\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 81.6666 - accuracy: 0.3939\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 4.7110 - accuracy: 0.6567\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 78.4351 - accuracy: 0.5606\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 4.6146 - accuracy: 0.6567\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 75.4349 - accuracy: 0.4848\n",
      "Epoch 6/10\n",
      "Epoch 1/10\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 72.8313 - accuracy: 0.6562Epoch 1/10\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 4.6169 - accuracy: 0.7164\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 72.3949 - accuracy: 0.6667\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 4.4548 - accuracy: 0.7015\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 69.7187 - accuracy: 0.5758\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 67.0164 - accuracy: 0.6364\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 64.5217 - accuracy: 0.6667\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 61.9837 - accuracy: 0.6212\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 1s 15ms/step - loss: 88.5275 - accuracy: 0.2090\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 18ms/step - loss: 89.0688 - accuracy: 0.2090\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 84.2202 - accuracy: 0.3582\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 85.6439 - accuracy: 0.4328\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 80.7783 - accuracy: 0.3582\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 82.3398 - accuracy: 0.5224\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 77.6063 - accuracy: 0.4478\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 79.7881 - accuracy: 0.5075\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 74.8996 - accuracy: 0.4030\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 77.3222 - accuracy: 0.5373\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 72.4233 - accuracy: 0.4328\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 74.9565 - accuracy: 0.6269\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 69.8473 - accuracy: 0.4179\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 72.8192 - accuracy: 0.5970\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 67.5127 - accuracy: 0.4627\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 70.7270 - accuracy: 0.6418\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 65.2622 - accuracy: 0.5075\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 68.6048 - accuracy: 0.5821\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 63.1845 - accuracy: 0.6119\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 66.4697 - accuracy: 0.6567\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 1s 66ms/step - loss: 6.3178 - accuracy: 0.1600\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 6.0260 - accuracy: 0.2200\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 5.6905 - accuracy: 0.3300\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 5.3899 - accuracy: 0.3600\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.3411 - accuracy: 0.4000\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 5.0959 - accuracy: 0.4600\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 4.8557 - accuracy: 0.5700\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.8574 - accuracy: 0.5400\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 4.8303 - accuracy: 0.5300\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.8024 - accuracy: 0.5700\n",
      "Best: 0.399584 using {'model__kernel_regularizer': 'l2'}\n",
      "0.11021984551396317 \t with: {'model__kernel_regularizer': None}\n",
      "0.3095662507427213 \t with: {'model__kernel_regularizer': 'l1'}\n",
      "0.3995840760546643 \t with: {'model__kernel_regularizer': 'l2'}\n",
      "0.36036838978015445 \t with: {'model__kernel_regularizer': 'l1_l2'}\n"
     ]
    }
   ],
   "source": [
    "GS = GridSearchCV(\n",
    "    estimator = model,\n",
    "    param_grid = param_grid,\n",
    "    scoring = 'accuracy',\n",
    "    n_jobs=-1,\n",
    "    cv = 3,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_result = GS.fit(X_train[:100], y_train[:100])\n",
    "\n",
    "# best result\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_,\n",
    "                             grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "# printing results for all combinations\n",
    "for mean, param in zip(means, params):\n",
    "    print(f\"{mean} \\t with: {param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1688311449525,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "5dNHJ2UpvWkq"
   },
   "outputs": [],
   "source": [
    "model = KerasClassifier(\n",
    "    model=create_model,\n",
    "    gru_hid_1=64, n_hid_1=64, n_hid_2=32,\n",
    "    dropout_rate=0.2,\n",
    "    batch_size=32,\n",
    "    kernel_regularizer='l2',\n",
    "    input_shape=(64,),\n",
    "    output_shape=5,\n",
    "    input_length=60,\n",
    "    embedding_matrix=co_occurrence_300d,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1688311449526,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "EKdpRxgfwDe0"
   },
   "outputs": [],
   "source": [
    "# kernel initializer\n",
    "kernel_initializers = ['glorot_uniform', 'he_normal']\n",
    "\n",
    "param_grid = dict(model__kernel_initializer=kernel_initializers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 77030,
     "status": "ok",
     "timestamp": 1688311526543,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "VNp33kWFwHVy",
    "outputId": "b12ee13e-e341-40e3-93fd-51af0065b112"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 2s 39ms/step - loss: 6.2226 - accuracy: 0.1862\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 2s 36ms/step - loss: 5.9056 - accuracy: 0.2793\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 2s 42ms/step - loss: 7.8854 - accuracy: 0.2523\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 5.5174 - accuracy: 0.3514\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 5.3952 - accuracy: 0.3694\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 42ms/step - loss: 6.2109 - accuracy: 0.2395\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 0s 44ms/step - loss: 7.0992 - accuracy: 0.3514\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 3s 50ms/step - loss: 7.8894 - accuracy: 0.2793\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 1s 45ms/step - loss: 5.0475 - accuracy: 0.4234\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 5.6846 - accuracy: 0.2635\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 1s 55ms/step - loss: 5.0664 - accuracy: 0.4294\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 3s 50ms/step - loss: 7.6086 - accuracy: 0.2365\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 6.7575 - accuracy: 0.3544\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 4.8993 - accuracy: 0.4144\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 1s 51ms/step - loss: 7.0723 - accuracy: 0.4054\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 5.2361 - accuracy: 0.3653\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 1s 51ms/step - loss: 4.6813 - accuracy: 0.5465\n",
      " 3/11 [=======>......................] - ETA: 0s - loss: 4.5406 - accuracy: 0.5000Epoch 5/10\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 7.0258 - accuracy: 0.4072\n",
      " 2/11 [====>.........................] - ETA: 0s - loss: 4.9611 - accuracy: 0.4219Epoch 3/10\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 6.2265 - accuracy: 0.4625\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 4.4813 - accuracy: 0.5255\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 1s 57ms/step - loss: 6.6148 - accuracy: 0.4625\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 4.9272 - accuracy: 0.4341\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 1s 57ms/step - loss: 4.4915 - accuracy: 0.5706\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 1s 54ms/step - loss: 6.6012 - accuracy: 0.5269\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 5.8979 - accuracy: 0.5105\n",
      " 5/11 [============>.................] - ETA: 0s - loss: 6.3354 - accuracy: 0.4625Epoch 6/10\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 6.3064 - accuracy: 0.4625\n",
      "11/11 [==============================] - 1s 53ms/step - loss: 4.6834 - accuracy: 0.4940\n",
      "Epoch 5/10\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 1s 65ms/step - loss: 4.2819 - accuracy: 0.5916\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 6.2554 - accuracy: 0.4940\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 5.5720 - accuracy: 0.5826\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 1s 57ms/step - loss: 4.2082 - accuracy: 0.6486\n",
      " 3/11 [=======>......................] - ETA: 0s - loss: 4.2165 - accuracy: 0.6250Epoch 7/10\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 4.4596 - accuracy: 0.5599\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 1s 53ms/step - loss: 5.9472 - accuracy: 0.5556\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 1s 54ms/step - loss: 4.0723 - accuracy: 0.6276\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 4.0204 - accuracy: 0.6907\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 1s 55ms/step - loss: 5.8308 - accuracy: 0.5928\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 1s 56ms/step - loss: 5.2010 - accuracy: 0.6667\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 4.2551 - accuracy: 0.6228\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 1s 53ms/step - loss: 5.6134 - accuracy: 0.6126\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 3.8880 - accuracy: 0.6306\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 1s 57ms/step - loss: 3.7497 - accuracy: 0.7568\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 1s 55ms/step - loss: 4.9571 - accuracy: 0.7027\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 5.5587 - accuracy: 0.6377\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 4.0898 - accuracy: 0.6497\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 1s 56ms/step - loss: 5.3914 - accuracy: 0.6637\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 1s 51ms/step - loss: 3.6895 - accuracy: 0.7057\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 4.6840 - accuracy: 0.7568\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 1s 53ms/step - loss: 3.6470 - accuracy: 0.7327\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 1s 60ms/step - loss: 5.1703 - accuracy: 0.7784\n",
      "11/11 [==============================] - 1s 53ms/step - loss: 3.7571 - accuracy: 0.7754\n",
      "Epoch 8/10\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 0s 45ms/step - loss: 3.5112 - accuracy: 0.7538\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 5.1366 - accuracy: 0.6787\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 1s 55ms/step - loss: 3.4548 - accuracy: 0.7958\n",
      "11/11 [==============================] - 1s 59ms/step - loss: 4.4489 - accuracy: 0.7958\n",
      "11/11 [==============================] - 1s 45ms/step - loss: 3.6437 - accuracy: 0.7545\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 4.9653 - accuracy: 0.7725\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 0s 42ms/step - loss: 4.8351 - accuracy: 0.7508\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 1s 14ms/steploss: 4.5808 - accuracy: 0.90\n",
      "6/6 [==============================] - 0s 10ms/steploss: 4.6221 - accuracy: 0.7857\n",
      "6/6 [==============================] - 1s 10ms/steploss: 4.7294 - accuracy: 0.82\n",
      "6/6 [==============================] - 0s 9ms/step loss: 4.5826 - accuracy: 0.80\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 4.7265 - accuracy: 0.8114\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 4.6011 - accuracy: 0.7868\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 4.5005 - accuracy: 0.8473\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "Epoch 1/10\n",
      "16/16 [==============================] - 2s 49ms/step - loss: 6.0304 - accuracy: 0.2740\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 5.3226 - accuracy: 0.3960\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 1s 51ms/step - loss: 4.9901 - accuracy: 0.4160\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 1s 62ms/step - loss: 4.5492 - accuracy: 0.5440\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 4.2244 - accuracy: 0.5920\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 3.9520 - accuracy: 0.6520\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 1s 81ms/step - loss: 3.7033 - accuracy: 0.6940\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 1s 80ms/step - loss: 3.4796 - accuracy: 0.7360\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 3.3058 - accuracy: 0.7720\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 3.0769 - accuracy: 0.8220\n",
      "Best: 0.469916 using {'model__kernel_initializer': 'glorot_uniform'}\n",
      "0.4699155905057355 \t with: {'model__kernel_initializer': 'glorot_uniform'}\n",
      "0.46393959069812185 \t with: {'model__kernel_initializer': 'he_normal'}\n"
     ]
    }
   ],
   "source": [
    "GS = GridSearchCV(\n",
    "    estimator = model,\n",
    "    param_grid = param_grid,\n",
    "    scoring = 'accuracy',\n",
    "    n_jobs=-1,\n",
    "    cv = 3,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_result = GS.fit(X_train[:500], y_train[:500])\n",
    "\n",
    "# best result\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_,\n",
    "                             grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "# printing results for all combinations\n",
    "for mean, param in zip(means, params):\n",
    "    print(f\"{mean} \\t with: {param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1688311526543,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "EXly9A5ywIkX"
   },
   "outputs": [],
   "source": [
    "optimizers = ['adam', 'sgd']\n",
    "\n",
    "param_grid = dict(model__optimizer=optimizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 69843,
     "status": "ok",
     "timestamp": 1688311596379,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "TR_gVUrYwepF",
    "outputId": "9e4d9596-cc1c-4f6b-f6b0-f2675b5b0ecd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 2s 41ms/step - loss: 6.2430 - accuracy: 0.2275\n",
      "11/11 [==============================] - 2s 40ms/step - loss: 6.2594 - accuracy: 0.2162\n",
      "Epoch 2/10\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 2s 49ms/step - loss: 6.0917 - accuracy: 0.2853\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 2s 42ms/step - loss: 6.2078 - accuracy: 0.2006\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 0s 42ms/step - loss: 5.9892 - accuracy: 0.3333\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 1s 45ms/step - loss: 5.8779 - accuracy: 0.3084\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 3s 49ms/step - loss: 6.1745 - accuracy: 0.2132\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 1s 53ms/step - loss: 5.5013 - accuracy: 0.3754\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 5.5542 - accuracy: 0.3204\n",
      "10/11 [==========================>...] - ETA: 0s - loss: 5.9964 - accuracy: 0.2625Epoch 3/10\n",
      "11/11 [==============================] - 3s 52ms/step - loss: 6.0078 - accuracy: 0.2583\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 5.7393 - accuracy: 0.3453\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 5.8211 - accuracy: 0.2964\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 5.9126 - accuracy: 0.3063\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 5.1803 - accuracy: 0.4565\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 0s 44ms/step - loss: 5.3061 - accuracy: 0.3503\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 1s 45ms/step - loss: 5.4716 - accuracy: 0.3453\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 5.6946 - accuracy: 0.3814\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 5.4919 - accuracy: 0.3772\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 1s 51ms/step - loss: 5.7905 - accuracy: 0.3333\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 1s 54ms/step - loss: 4.8908 - accuracy: 0.5165\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 1s 53ms/step - loss: 4.8458 - accuracy: 0.5060\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 5.5195 - accuracy: 0.4144\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 1s 61ms/step - loss: 5.1704 - accuracy: 0.3934\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 1s 63ms/step - loss: 5.4323 - accuracy: 0.4281\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 1s 55ms/step - loss: 5.4035 - accuracy: 0.4144\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 1s 53ms/step - loss: 4.6136 - accuracy: 0.5539\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 1s 53ms/step - loss: 5.4621 - accuracy: 0.4234\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 1s 57ms/step - loss: 4.6103 - accuracy: 0.5255\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 1s 50ms/step - loss: 4.8910 - accuracy: 0.4535\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 1s 63ms/step - loss: 5.3580 - accuracy: 0.4281\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 1s 68ms/step - loss: 5.3620 - accuracy: 0.4895\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 1s 66ms/step - loss: 5.2881 - accuracy: 0.4745\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 4.2941 - accuracy: 0.6276\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 4.3041 - accuracy: 0.6228\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 1s 66ms/step - loss: 4.5350 - accuracy: 0.5495\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 1s 61ms/step - loss: 5.2109 - accuracy: 0.5120\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 1s 55ms/step - loss: 5.3346 - accuracy: 0.4234\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 1s 58ms/step - loss: 5.2999 - accuracy: 0.4595\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 1s 59ms/step - loss: 4.1645 - accuracy: 0.6456\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 1s 58ms/step - loss: 4.0676 - accuracy: 0.6587\n",
      " 5/11 [============>.................] - ETA: 0s - loss: 5.2118 - accuracy: 0.5000Epoch 8/10\n",
      "11/11 [==============================] - 1s 60ms/step - loss: 4.3401 - accuracy: 0.5706\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 4.0608 - accuracy: 0.7500Epoch 7/10\n",
      "11/11 [==============================] - 1s 61ms/step - loss: 5.2362 - accuracy: 0.5090\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 1s 60ms/step - loss: 5.2052 - accuracy: 0.5045\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 1s 58ms/step - loss: 5.2439 - accuracy: 0.5105\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 1s 58ms/step - loss: 4.0060 - accuracy: 0.6877\n",
      " 7/11 [==================>...........] - ETA: 0s - loss: 5.2171 - accuracy: 0.5000Epoch 9/10\n",
      "11/11 [==============================] - 1s 61ms/step - loss: 3.8582 - accuracy: 0.7216\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 1s 59ms/step - loss: 4.0986 - accuracy: 0.6396\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 1s 55ms/step - loss: 5.1300 - accuracy: 0.5359\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 1s 61ms/step - loss: 5.1016 - accuracy: 0.5495\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 1s 58ms/step - loss: 5.1381 - accuracy: 0.5165\n",
      "11/11 [==============================] - 1s 57ms/step - loss: 3.7309 - accuracy: 0.7568\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 1s 56ms/step - loss: 3.8606 - accuracy: 0.6787\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 1s 63ms/step - loss: 3.7157 - accuracy: 0.7515\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 3.7146 - accuracy: 0.7500Epoch 10/10\n",
      "11/11 [==============================] - 1s 59ms/step - loss: 4.9974 - accuracy: 0.6018\n",
      "11/11 [==============================] - 1s 61ms/step - loss: 4.9790 - accuracy: 0.5946\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 3.5438 - accuracy: 0.7928\n",
      "11/11 [==============================] - 1s 55ms/step - loss: 3.6887 - accuracy: 0.7117\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 1s 17ms/steploss: 3.5315 - accuracy: 0.74\n",
      "11/11 [==============================] - 1s 58ms/step - loss: 3.5455 - accuracy: 0.7425\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 4.9925 - accuracy: 0.5616\n",
      "6/6 [==============================] - 1s 10ms/steploss: 3.5678 - accuracy: 0.7127\n",
      "11/11 [==============================] - 0s 40ms/step - loss: 3.5783 - accuracy: 0.7147\n",
      "6/6 [==============================] - 1s 8ms/step\n",
      "6/6 [==============================] - 0s 8ms/step\n",
      "6/6 [==============================] - 1s 8ms/step\n",
      "6/6 [==============================] - 0s 7ms/step\n",
      "Epoch 1/10\n",
      "16/16 [==============================] - 4s 82ms/step - loss: 6.0619 - accuracy: 0.2460\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 5.8154 - accuracy: 0.3160\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 5.5992 - accuracy: 0.3780\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 1s 65ms/step - loss: 5.4010 - accuracy: 0.4380\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 5.3791 - accuracy: 0.4420\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 5.2717 - accuracy: 0.4780\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 1s 59ms/step - loss: 5.1108 - accuracy: 0.5240\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 5.0139 - accuracy: 0.5580\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 5.0113 - accuracy: 0.5600\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 1s 65ms/step - loss: 4.9650 - accuracy: 0.5960\n",
      "Best: 0.417815 using {'model__optimizer': 'sgd'}\n",
      "0.4120313589688094 \t with: {'model__optimizer': 'adam'}\n",
      "0.4178149724647091 \t with: {'model__optimizer': 'sgd'}\n"
     ]
    }
   ],
   "source": [
    "GS = GridSearchCV(\n",
    "    estimator = model,\n",
    "    param_grid = param_grid,\n",
    "    scoring = 'accuracy',\n",
    "    n_jobs=-1,\n",
    "    cv = 3,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_result = GS.fit(X_train[:500], y_train[:500])\n",
    "\n",
    "# best result\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_,\n",
    "                             grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "# printing results for all combinations\n",
    "for mean, param in zip(means, params):\n",
    "    print(f\"{mean} \\t with: {param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "executionInfo": {
     "elapsed": 459,
     "status": "ok",
     "timestamp": 1688311596827,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "oRO2ZpNBw4ZT"
   },
   "outputs": [],
   "source": [
    "# Final Model\n",
    "model = create_model(gru_hid_1=64, n_hid_1=64, n_hid_2=32,\n",
    "                     dropout_rate=0.2,\n",
    "                     kernel_regularizer='l2',\n",
    "                     input_shape=(64,),\n",
    "                     output_shape=5,\n",
    "                     input_length=60,\n",
    "                     embedding_matrix=co_occurrence_300d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 142955,
     "status": "ok",
     "timestamp": 1688312154776,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "s3SMqpL8yuwH",
    "outputId": "ce972240-1cdb-4a1a-dc37-1d180f5f668a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "171/171 [==============================] - 10s 49ms/step - loss: 4.6428 - accuracy: 0.3758 - val_loss: 3.4943 - val_accuracy: 0.5348\n",
      "Epoch 2/20\n",
      "171/171 [==============================] - 10s 57ms/step - loss: 3.0634 - accuracy: 0.5190 - val_loss: 2.5767 - val_accuracy: 0.5531\n",
      "Epoch 3/20\n",
      "171/171 [==============================] - 13s 73ms/step - loss: 2.3382 - accuracy: 0.5744 - val_loss: 2.2251 - val_accuracy: 0.5480\n",
      "Epoch 4/20\n",
      "171/171 [==============================] - 10s 59ms/step - loss: 2.0146 - accuracy: 0.5974 - val_loss: 1.9484 - val_accuracy: 0.5641\n",
      "Epoch 5/20\n",
      "171/171 [==============================] - 13s 74ms/step - loss: 1.7905 - accuracy: 0.6143 - val_loss: 1.8892 - val_accuracy: 0.5502\n",
      "Epoch 6/20\n",
      "171/171 [==============================] - 11s 67ms/step - loss: 1.6814 - accuracy: 0.6311 - val_loss: 1.7902 - val_accuracy: 0.5912\n",
      "Epoch 7/20\n",
      "171/171 [==============================] - 12s 71ms/step - loss: 1.6383 - accuracy: 0.6419 - val_loss: 1.8255 - val_accuracy: 0.5648\n",
      "Epoch 8/20\n",
      "171/171 [==============================] - 14s 84ms/step - loss: 1.6127 - accuracy: 0.6537 - val_loss: 1.8134 - val_accuracy: 0.5678\n",
      "Epoch 9/20\n",
      "171/171 [==============================] - 13s 75ms/step - loss: 1.5679 - accuracy: 0.6643 - val_loss: 1.8222 - val_accuracy: 0.5553\n",
      "Epoch 10/20\n",
      "171/171 [==============================] - 12s 71ms/step - loss: 1.5413 - accuracy: 0.6771 - val_loss: 1.8245 - val_accuracy: 0.5495\n",
      "Epoch 11/20\n",
      "171/171 [==============================] - 13s 77ms/step - loss: 1.5140 - accuracy: 0.6899 - val_loss: 1.8623 - val_accuracy: 0.5707\n",
      "Epoch 12/20\n",
      "171/171 [==============================] - 14s 85ms/step - loss: 1.5366 - accuracy: 0.6907 - val_loss: 1.9068 - val_accuracy: 0.5458\n",
      "Epoch 13/20\n",
      "171/171 [==============================] - 13s 75ms/step - loss: 1.5356 - accuracy: 0.6943 - val_loss: 1.9320 - val_accuracy: 0.5538\n",
      "Epoch 14/20\n",
      "171/171 [==============================] - 13s 76ms/step - loss: 1.5175 - accuracy: 0.7112 - val_loss: 2.0378 - val_accuracy: 0.5363\n",
      "Epoch 15/20\n",
      "171/171 [==============================] - 13s 77ms/step - loss: 1.5370 - accuracy: 0.7194 - val_loss: 1.9875 - val_accuracy: 0.5634\n",
      "Epoch 16/20\n",
      "171/171 [==============================] - 12s 70ms/step - loss: 1.5352 - accuracy: 0.7264 - val_loss: 2.0483 - val_accuracy: 0.5451\n",
      "Epoch 17/20\n",
      "171/171 [==============================] - 14s 80ms/step - loss: 1.5180 - accuracy: 0.7267 - val_loss: 2.0051 - val_accuracy: 0.5480\n",
      "Epoch 18/20\n",
      "171/171 [==============================] - 13s 74ms/step - loss: 1.5048 - accuracy: 0.7383 - val_loss: 2.0615 - val_accuracy: 0.5465\n",
      "Epoch 19/20\n",
      "171/171 [==============================] - 13s 74ms/step - loss: 1.5376 - accuracy: 0.7370 - val_loss: 2.1023 - val_accuracy: 0.5385\n",
      "Epoch 20/20\n",
      "171/171 [==============================] - 12s 71ms/step - loss: 1.5469 - accuracy: 0.7394 - val_loss: 2.0701 - val_accuracy: 0.5385\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=32, epochs=20, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t9hjzadARWD7"
   },
   "source": [
    "# 6) How would you evaluate the generalization capabilities of the mdolel on unseen data?\n",
    "\n",
    "I evaluated the generalization capabilities of the model on unseen data by computing the evaluation metrics and generating a confusion matrix. The evaluation metrics, such as the test loss and accuracy, provide an overall assessment of the model's performance on the test data. Additionally, the confusion matrix allows us to analyze the model's predictions across different classes. By visualizing the confusion matrix, we can gain insights into the model's performance in terms of correctly predicting the different star ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 465,
     "status": "ok",
     "timestamp": 1688312155235,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "14X28cvwqUuf",
    "outputId": "309856d7-5880-4771-ed12-2a835daff1ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 1s 23ms/step - loss: 2.1278 - accuracy: 0.5354\n",
      "Test Loss: 2.1277730464935303\n",
      "Test Accuracy: 0.5354422926902771\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "executionInfo": {
     "elapsed": 2931,
     "status": "ok",
     "timestamp": 1688312455451,
     "user": {
      "displayName": "ANDREA LOLLI",
      "userId": "08743711697490110255"
     },
     "user_tz": -120
    },
    "id": "IczpiDwrPv3T",
    "outputId": "460f33ba-08bd-4b6d-ee2c-c5d79c33f189"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 1s 15ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert one-hot encoded true labels to class indices\n",
    "y_true_indices = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Convert predicted labels to class indices\n",
    "y_pred_indices = np.argmax(model.predict(X_test), axis=1)\n",
    "\n",
    "# Create the confusion matrix\n",
    "cm = confusion_matrix(y_true_indices, y_pred_indices)\n",
    "\n",
    "# Define class labels\n",
    "class_labels = ['1 star', '2 stars', '3 stars', '4 starts', '5 stars']\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AWnAj_boQOwi"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMHTwH8Ec68bqiI9QqhKDxV",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
